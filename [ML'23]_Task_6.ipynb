{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SI-lbeuMtcp"
      },
      "source": [
        "# Load dataset from kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ApCnYX0tEOp3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"nadaazabmohamed\" # from kaggle.json\n",
        "os.environ['KAGGLE_KEY'] =  \"bd4fb6609e0f745b732db37c5c173a65\" # from kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVLQdoPlEj_Q",
        "outputId": "20839528-2246-46ff-8573-627b6af98975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading support23-fashion-classification.zip to /content\n",
            " 93% 26.0M/28.0M [00:02<00:00, 16.5MB/s]\n",
            "100% 28.0M/28.0M [00:02<00:00, 11.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c support23-fashion-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FrFBY2AFGI3",
        "outputId": "88f4b758-1b77-4673-c604-c76d855b0b83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/support23-fashion-classification.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/support23-fashion-classification.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUecfyShbtbG",
        "outputId": "3ed9d7ed-ccfc-41ed-b87d-07b65cd96b46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2-cp310-cp310-manylinux2014_x86_64.whl (98.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2022.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "j5hVOI_uL1Fc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import csv\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import AdaBoostClassifier,BaggingClassifier,GradientBoostingClassifier,StackingClassifier \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss,accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zajw9oBdOQNY"
      },
      "source": [
        "Mount drive folder to workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6DAQrbjOkDP"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5VzX7h59cYAb"
      },
      "outputs": [],
      "source": [
        "datatrain=pd.read_csv(\"train.csv\")\n",
        "datatest=pd.read_csv(\"test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "eRxK-oBvNfZv",
        "outputId": "8eaf6682-4958-400f-840e-8dd6678e4ef7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      3       0       0       0       0       0       0      14      85   \n",
              "1      1       0       0       0       0       0       0       0       0   \n",
              "2      3       0       0       0       0       0       0       0       0   \n",
              "3      8       0       0       0       0       0       0       0       0   \n",
              "4      3       0       0       0       0       0       2       0       0   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0      76  ...        45        52       102         2         0         2   \n",
              "1      34  ...       193        49         0         0         0         0   \n",
              "2       0  ...         0         0         0         0         0         0   \n",
              "3       0  ...         0         0         0         0         0         0   \n",
              "4      47  ...       144        97        67        22         0         1   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0         0         0         0         0  \n",
              "1         0         0         0         0  \n",
              "2         0         0         0         0  \n",
              "3         0         0         0         0  \n",
              "4         0         0         0         0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-320ed254-1d7f-43a3-a710-90e325aa4105\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>85</td>\n",
              "      <td>76</td>\n",
              "      <td>...</td>\n",
              "      <td>45</td>\n",
              "      <td>52</td>\n",
              "      <td>102</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>...</td>\n",
              "      <td>193</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>...</td>\n",
              "      <td>144</td>\n",
              "      <td>97</td>\n",
              "      <td>67</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-320ed254-1d7f-43a3-a710-90e325aa4105')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-320ed254-1d7f-43a3-a710-90e325aa4105 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-320ed254-1d7f-43a3-a710-90e325aa4105');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "datatrain.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "o9ukHLbCcvWn",
        "outputId": "65091960-818c-4f7b-c3e0-b00e584387b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
              "0       0       0       0       0       0       0       0       0       0   \n",
              "1       0       0       0       0       0       0       0      30      86   \n",
              "2       0       0       0       0       1       0       0       0       0   \n",
              "3       0       0       0       0       0       0       0       5      97   \n",
              "4       0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0        0  ...        88        14         0         0         0         0   \n",
              "1        0  ...        15        38        77        73         0         0   \n",
              "2       48  ...         6        17         0         0         9       193   \n",
              "3      166  ...       233       226       215       234        31         0   \n",
              "4        4  ...         0         0         0         2         0         2   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0         0         0         0         0  \n",
              "1         2         0         0         0  \n",
              "2       208       113         0         0  \n",
              "3         2         0         0         0  \n",
              "4        50         0         0         0  \n",
              "\n",
              "[5 rows x 784 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07476c08-53cf-4ab4-bed9-660138cdf16e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>88</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>86</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>15</td>\n",
              "      <td>38</td>\n",
              "      <td>77</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>193</td>\n",
              "      <td>208</td>\n",
              "      <td>113</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>97</td>\n",
              "      <td>166</td>\n",
              "      <td>...</td>\n",
              "      <td>233</td>\n",
              "      <td>226</td>\n",
              "      <td>215</td>\n",
              "      <td>234</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 784 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07476c08-53cf-4ab4-bed9-660138cdf16e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07476c08-53cf-4ab4-bed9-660138cdf16e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07476c08-53cf-4ab4-bed9-660138cdf16e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "datatest.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQMEvOlqcsSR"
      },
      "source": [
        "# Train a Decision Tree and a Random Forest model using [scikit-learn](https://scikit-learn.org/stable/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEaxRFt4cDQb",
        "outputId": "25b7516a-b3f6-4f2e-80c6-de38afc95379"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# X is the variable holding your samples\n",
        "# y is the variable holding your labels\n",
        "X=datatrain.iloc[:,1:785].values\n",
        "y=datatrain['label']\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ref3ytHUHU69",
        "outputId": "10e9c9fc-ccf1-4379-d143-b962a4f8bc67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        3\n",
              "1        1\n",
              "2        3\n",
              "3        8\n",
              "4        3\n",
              "        ..\n",
              "39995    2\n",
              "39996    1\n",
              "39997    4\n",
              "39998    3\n",
              "39999    1\n",
              "Name: label, Length: 40000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozMldI0Le97o",
        "outputId": "7ed9ecc2-8875-45f2-b194-5b1e0f64c17e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# data label \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "y_enc = one_hot_encoder.fit_transform(datatrain.iloc[:,0:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mihxXwPrhdus",
        "outputId": "7d5339dd-6239-424c-bf3d-84356b6a0144"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "y_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4l-u3Gek6Ge",
        "outputId": "182614d1-61ce-4844-8ae4-146d14832c62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#split dataset to train and test\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y_enc,test_size=.2,random_state=2)\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_hiBxvhsx7_",
        "outputId": "c2ada876-5eae-4801-fc80-03461cbc9eae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21370    9\n",
              "2470     4\n",
              "13767    4\n",
              "13316    8\n",
              "26374    7\n",
              "        ..\n",
              "20757    1\n",
              "32103    4\n",
              "30403    8\n",
              "21243    7\n",
              "2732     6\n",
              "Name: label, Length: 32000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#split dataset to train and test\n",
        "X_train_not,X_test_not,y_train_not,y_test_not=train_test_split(X,y,test_size=.2,random_state=0)\n",
        "y_train_not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5pq0AzAqAuq"
      },
      "source": [
        "# ***DecisionTree***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "VsTWgMQzl8pF",
        "outputId": "49a4beaa-e8c5-46fc-cee0-b5177abd44b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=800, max_leaf_nodes=100)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=800, max_leaf_nodes=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=800, max_leaf_nodes=100)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "DecisionTree=DecisionTreeClassifier(max_leaf_nodes=100, max_depth=800)\n",
        "DecisionTree.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ouAwRY_SmBx8"
      },
      "outputs": [],
      "source": [
        "y_pred=DecisionTree.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqd5JANqmGhN",
        "outputId": "56298035-8e17-499d-a299-615ada6e1f08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.757625"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "accuracy=accuracy_score(y_test,y_pred)\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NZSw7g-AmHXC"
      },
      "outputs": [],
      "source": [
        "# save your model\n",
        "pickle.dump(DecisionTree,open(\"DecisionTree.pkl\",'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jobKefAppv5L"
      },
      "source": [
        "# **RandomForest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "9U2eqnq0mJgg",
        "outputId": "2c0b9210-617f-4ead-87d6-4f276624edac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=85, max_leaf_nodes=85)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=85, max_leaf_nodes=85)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=85, max_leaf_nodes=85)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "RandomForest=RandomForestClassifier(max_leaf_nodes=85, max_depth=85)\n",
        "RandomForest.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "v852fR-2mPHT"
      },
      "outputs": [],
      "source": [
        "y_pred_Random=RandomForest.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pY5y1PFmPs7",
        "outputId": "5a6e0b63-3ac1-4433-dd77-83f2a43deeff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.71775"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "accuaracy_Random=accuracy_score(y_test,y_pred_Random)\n",
        "accuaracy_Random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "SdWqSp3tmQak"
      },
      "outputs": [],
      "source": [
        "pickle.dump(RandomForest,open(\"RandomForest.pkl\",'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow8uo6lWqKcr"
      },
      "source": [
        "# ***logistic***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLtcP-mcmQ4U",
        "outputId": "3dde533b-e183-4a3a-c56d-499a3e855b94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8385"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic=LogisticRegression(multi_class='ovr',max_iter=100,)\n",
        "logistic.fit(X_train_not,y_train_not)\n",
        "y_pred_model=logistic.predict(X_test_not)\n",
        "accurecy_sk=accuracy_score(y_test_not,y_pred_model)\n",
        "accurecy_sk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "BeLBrlJimUUi"
      },
      "outputs": [],
      "source": [
        "pickle.dump(logistic,open(\"logistic.pkl\",'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFXIKLLyqUis"
      },
      "source": [
        "# ***AdaBoost***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "5mK4fhhKnAUY",
        "outputId": "082eea6e-2c2a-48b2-d517-3671da6551a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=800,\n",
              "                                                         max_leaf_nodes=100),\n",
              "                   learning_rate=0.5, n_estimators=100, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=800,\n",
              "                                                         max_leaf_nodes=100),\n",
              "                   learning_rate=0.5, n_estimators=100, random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=800, max_leaf_nodes=100)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=800, max_leaf_nodes=100)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=800,\n",
              "                                                         max_leaf_nodes=100),\n",
              "                   learning_rate=0.5, n_estimators=100, random_state=42)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize AdaBoost with the base learner\n",
        "adaboost = AdaBoostClassifier(base_estimator=DecisionTree, n_estimators=100, learning_rate=.5, random_state=42)\n",
        "adaboost.fit(X_train_not,y_train_not)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3joiavonAUa"
      },
      "outputs": [],
      "source": [
        "y_pred_ada=adaboost.predict(X_test_not)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVW2J2Z2nAUa",
        "outputId": "91deb421-208b-468c-ea2b-565db5beae9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8100941945279152"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "accuaracy_ada=f1_score(y_test_not,y_pred_ada,average='weighted')\n",
        "accuaracy_ada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBKKTyt2wiGL",
        "outputId": "aec2236d-afc6-4222-b454-4a72cf426502"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.80925"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acc=accuracy_score(y_test_not,y_pred_ada)\n",
        "acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTDTaBrlnAUb"
      },
      "outputs": [],
      "source": [
        "pickle.dump(AdaBoostClassifier,open(\"AdaBoostClassifier.pkl\",'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYfBZB2Vqbv9"
      },
      "source": [
        "# ***Bagging***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXXEh5eNJS9z"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "seed=7\n",
        "kfold=KFold(n_splits=10,random_state=seed,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsCsUAs0ncVB"
      },
      "outputs": [],
      "source": [
        "BaggingClassifier=BaggingClassifier(base_estimator=DecisionTree, n_estimators=10,random_state=seed,n_jobs=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tThY95Z6KKmq",
        "outputId": "d8834d4c-49d4-443f-de1d-d354eddb4a60"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "result=cross_val_score(BaggingClassifier,X_train_not,y_train_not,cv=kfold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xtk-mEZncVD",
        "outputId": "3f6fb13a-abf1-41a6-8f7f-ba835f06cd33"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "BaggingClassifier.fit(X_train_not,y_train_not)\n",
        "y_pred_bag=BaggingClassifier.predict(X_test_not)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ldwy_1TncVD",
        "outputId": "29965a22-ec2c-4795-b362-71316aba2a09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8194579881174842"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "accuaracy_bag=f1_score(y_test_not,y_pred_bag,average='weighted')\n",
        "accuaracy_bag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqfXSgMcncVE"
      },
      "outputs": [],
      "source": [
        "pickle.dump(BaggingClassifier,open(\"BaggingClassifier.pkl\",'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIEs4DCPqiIC"
      },
      "source": [
        "# ***GradientBoosting***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "pZFHaEIMnu5G",
        "outputId": "bfbc2e5a-1089-4ca5-8bda-2ab3a7f4b220"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=1, max_depth=1, n_estimators=20,\n",
              "                           random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=1, max_depth=1, n_estimators=20,\n",
              "                           random_state=0)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "GradientBoostingClassifier(learning_rate=1, max_depth=1, n_estimators=20,\n",
              "                           random_state=0)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "GradientBoostingClassifier=GradientBoostingClassifier(n_estimators=20, learning_rate=1,max_depth=1, random_state=0)\n",
        "GradientBoostingClassifier.fit(X_train_not,y_train_not)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9zpNsBJnu5H"
      },
      "outputs": [],
      "source": [
        "y_pred_grad=GradientBoostingClassifier.predict(X_test_not)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL8vYmJUnu5H",
        "outputId": "231845ad-54d0-4417-9d49-11b9ff11723d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.66264015367465"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuaracy_grad=f1_score(y_test_not,y_pred_grad,average='weighted')\n",
        "accuaracy_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjTHHQSsnu5I"
      },
      "outputs": [],
      "source": [
        "pickle.dump(GradientBoostingClassifier,open(\"GradientBoostingClassifier.pkl\",'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2x1WRc7qtbb"
      },
      "source": [
        "# ***Stacking***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nB60m-6vjmGE",
        "outputId": "1386c414-5823-40e3-e384-e4fa92299ce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "dtc =  DecisionTreeClassifier()\n",
        "rfc = RandomForestClassifier()\n",
        "clf = [('dtc',DecisionTree),('LOG',logistic)]\n",
        "lr = RandomForest\n",
        "stack_model = StackingClassifier( estimators = clf,final_estimator = lr)\n",
        "score = cross_val_score(stack_model,X_train_not,y_train_not,cv = 5,scoring = 'accuracy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Ptopn_cwoGHN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e265d3-5cec-4b7a-97e2-a02ad9ade764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.850349208714468"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "stack_model.fit(X_train_not,y_train_not)\n",
        "y_pred_stack=stack_model.predict(X_test_not)\n",
        "accuaracy_stack=f1_score(y_test_not,y_pred_stack,average='weighted')\n",
        "accuaracy_stack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "KvOs8IULoGHN"
      },
      "outputs": [],
      "source": [
        "pickle.dump(StackingClassifier,open(\"StackingClassifier.pkl\",'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xLaL3RZq0yF"
      },
      "source": [
        "# ***CatBoost***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jlyUp-G4ophK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c237dd79-3f67-4363-c267-d7f6a898c020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 1.5654318\ttotal: 807ms\tremaining: 13m 26s\n",
            "1:\tlearn: 1.3064028\ttotal: 1.3s\tremaining: 10m 50s\n",
            "2:\tlearn: 1.1321049\ttotal: 2.08s\tremaining: 11m 33s\n",
            "3:\tlearn: 1.0104855\ttotal: 2.73s\tremaining: 11m 18s\n",
            "4:\tlearn: 0.9219345\ttotal: 3.33s\tremaining: 11m 3s\n",
            "5:\tlearn: 0.9047162\ttotal: 4.02s\tremaining: 11m 6s\n",
            "6:\tlearn: 0.8376177\ttotal: 4.97s\tremaining: 11m 45s\n",
            "7:\tlearn: 0.7846715\ttotal: 6.21s\tremaining: 12m 50s\n",
            "8:\tlearn: 0.9391901\ttotal: 6.92s\tremaining: 12m 41s\n",
            "9:\tlearn: 1.3657378\ttotal: 7.43s\tremaining: 12m 16s\n",
            "10:\tlearn: 1.3352791\ttotal: 8.05s\tremaining: 12m 3s\n",
            "11:\tlearn: 1.3211670\ttotal: 8.6s\tremaining: 11m 48s\n",
            "12:\tlearn: 1.2978393\ttotal: 9.32s\tremaining: 11m 48s\n",
            "13:\tlearn: 1.2756802\ttotal: 10s\tremaining: 11m 45s\n",
            "14:\tlearn: 1.2601261\ttotal: 10.5s\tremaining: 11m 31s\n",
            "15:\tlearn: 1.2474967\ttotal: 11.1s\tremaining: 11m 21s\n",
            "16:\tlearn: 1.2383540\ttotal: 11.5s\tremaining: 11m 7s\n",
            "17:\tlearn: 1.2250771\ttotal: 12.3s\tremaining: 11m 8s\n",
            "18:\tlearn: 1.2102179\ttotal: 12.9s\tremaining: 11m 6s\n",
            "19:\tlearn: 1.2009830\ttotal: 13.5s\tremaining: 10m 59s\n",
            "20:\tlearn: 1.1864888\ttotal: 14.2s\tremaining: 11m\n",
            "21:\tlearn: 1.1355724\ttotal: 15.2s\tremaining: 11m 17s\n",
            "22:\tlearn: 1.1301401\ttotal: 16.3s\tremaining: 11m 31s\n",
            "23:\tlearn: 1.1237842\ttotal: 16.9s\tremaining: 11m 26s\n",
            "24:\tlearn: 1.1185557\ttotal: 17.9s\tremaining: 11m 36s\n",
            "25:\tlearn: 1.1149670\ttotal: 18.8s\tremaining: 11m 44s\n",
            "26:\tlearn: 1.1111287\ttotal: 19.3s\tremaining: 11m 36s\n",
            "27:\tlearn: 1.1034274\ttotal: 20s\tremaining: 11m 34s\n",
            "28:\tlearn: 1.1032056\ttotal: 20.5s\tremaining: 11m 26s\n",
            "29:\tlearn: 1.0987270\ttotal: 21.2s\tremaining: 11m 24s\n",
            "30:\tlearn: 1.0903741\ttotal: 21.9s\tremaining: 11m 25s\n",
            "31:\tlearn: 1.0900661\ttotal: 22.4s\tremaining: 11m 17s\n",
            "32:\tlearn: 1.0846730\ttotal: 23.1s\tremaining: 11m 16s\n",
            "33:\tlearn: 1.0835042\ttotal: 23.6s\tremaining: 11m 9s\n",
            "34:\tlearn: 1.0732080\ttotal: 24s\tremaining: 11m 3s\n",
            "35:\tlearn: 1.0731117\ttotal: 24.5s\tremaining: 10m 56s\n",
            "36:\tlearn: 1.0692778\ttotal: 25s\tremaining: 10m 49s\n",
            "37:\tlearn: 1.0671250\ttotal: 25.4s\tremaining: 10m 43s\n",
            "38:\tlearn: 1.0527035\ttotal: 26s\tremaining: 10m 41s\n",
            "39:\tlearn: 1.0432610\ttotal: 26.7s\tremaining: 10m 39s\n",
            "40:\tlearn: 1.0419580\ttotal: 27.1s\tremaining: 10m 34s\n",
            "41:\tlearn: 1.0357463\ttotal: 27.6s\tremaining: 10m 30s\n",
            "42:\tlearn: 1.0321515\ttotal: 28.3s\tremaining: 10m 29s\n",
            "43:\tlearn: 1.0315568\ttotal: 28.7s\tremaining: 10m 24s\n",
            "44:\tlearn: 1.0299480\ttotal: 29.4s\tremaining: 10m 24s\n",
            "45:\tlearn: 1.0254361\ttotal: 30.4s\tremaining: 10m 29s\n",
            "46:\tlearn: 1.0217481\ttotal: 31.4s\tremaining: 10m 35s\n",
            "47:\tlearn: 1.0215498\ttotal: 31.8s\tremaining: 10m 31s\n",
            "48:\tlearn: 1.0179820\ttotal: 32.4s\tremaining: 10m 28s\n",
            "49:\tlearn: 1.0153646\ttotal: 32.9s\tremaining: 10m 25s\n",
            "50:\tlearn: 1.0150848\ttotal: 33.4s\tremaining: 10m 21s\n",
            "51:\tlearn: 1.0053592\ttotal: 34.2s\tremaining: 10m 23s\n",
            "52:\tlearn: 1.0048062\ttotal: 34.6s\tremaining: 10m 18s\n",
            "53:\tlearn: 1.0014620\ttotal: 35.1s\tremaining: 10m 15s\n",
            "54:\tlearn: 1.0007795\ttotal: 35.6s\tremaining: 10m 11s\n",
            "55:\tlearn: 0.9980459\ttotal: 36.1s\tremaining: 10m 8s\n",
            "56:\tlearn: 0.9927596\ttotal: 36.7s\tremaining: 10m 7s\n",
            "57:\tlearn: 0.9918953\ttotal: 37.2s\tremaining: 10m 3s\n",
            "58:\tlearn: 0.9918194\ttotal: 37.6s\tremaining: 10m\n",
            "59:\tlearn: 0.9908642\ttotal: 38.1s\tremaining: 9m 56s\n",
            "60:\tlearn: 0.9799424\ttotal: 38.6s\tremaining: 9m 53s\n",
            "61:\tlearn: 0.8589184\ttotal: 39.1s\tremaining: 9m 51s\n",
            "62:\tlearn: 0.8557273\ttotal: 39.5s\tremaining: 9m 48s\n",
            "63:\tlearn: 0.8540551\ttotal: 40s\tremaining: 9m 44s\n",
            "64:\tlearn: 0.8198252\ttotal: 40.5s\tremaining: 9m 42s\n",
            "65:\tlearn: 0.8152905\ttotal: 41s\tremaining: 9m 40s\n",
            "66:\tlearn: 0.7894373\ttotal: 41.7s\tremaining: 9m 41s\n",
            "67:\tlearn: 0.7891525\ttotal: 42.6s\tremaining: 9m 44s\n",
            "68:\tlearn: 0.7882199\ttotal: 43.5s\tremaining: 9m 46s\n",
            "69:\tlearn: 0.7881067\ttotal: 43.9s\tremaining: 9m 43s\n",
            "70:\tlearn: 0.7862986\ttotal: 44.4s\tremaining: 9m 40s\n",
            "71:\tlearn: 0.7850723\ttotal: 44.9s\tremaining: 9m 38s\n",
            "72:\tlearn: 0.7831593\ttotal: 45.4s\tremaining: 9m 36s\n",
            "73:\tlearn: 0.7764363\ttotal: 46s\tremaining: 9m 35s\n",
            "74:\tlearn: 0.7738145\ttotal: 46.6s\tremaining: 9m 34s\n",
            "75:\tlearn: 0.7713107\ttotal: 47.1s\tremaining: 9m 32s\n",
            "76:\tlearn: 0.7699755\ttotal: 47.6s\tremaining: 9m 30s\n",
            "77:\tlearn: 0.7673257\ttotal: 48.1s\tremaining: 9m 29s\n",
            "78:\tlearn: 0.7444289\ttotal: 48.6s\tremaining: 9m 26s\n",
            "79:\tlearn: 0.7436548\ttotal: 49.1s\tremaining: 9m 24s\n",
            "80:\tlearn: 0.7425905\ttotal: 49.6s\tremaining: 9m 22s\n",
            "81:\tlearn: 0.7395145\ttotal: 50.2s\tremaining: 9m 21s\n",
            "82:\tlearn: 0.7385711\ttotal: 50.7s\tremaining: 9m 20s\n",
            "83:\tlearn: 0.7358908\ttotal: 51.2s\tremaining: 9m 18s\n",
            "84:\tlearn: 0.7349953\ttotal: 51.8s\tremaining: 9m 18s\n",
            "85:\tlearn: 0.7333524\ttotal: 52.4s\tremaining: 9m 16s\n",
            "86:\tlearn: 0.7318651\ttotal: 52.9s\tremaining: 9m 15s\n",
            "87:\tlearn: 0.7274786\ttotal: 53.5s\tremaining: 9m 14s\n",
            "88:\tlearn: 0.7254811\ttotal: 54.7s\tremaining: 9m 19s\n",
            "89:\tlearn: 0.7245627\ttotal: 55.8s\tremaining: 9m 24s\n",
            "90:\tlearn: 0.7213847\ttotal: 56.3s\tremaining: 9m 22s\n",
            "91:\tlearn: 0.7200973\ttotal: 57s\tremaining: 9m 22s\n",
            "92:\tlearn: 0.7184571\ttotal: 57.6s\tremaining: 9m 21s\n",
            "93:\tlearn: 0.7136601\ttotal: 58.2s\tremaining: 9m 20s\n",
            "94:\tlearn: 0.7121903\ttotal: 58.7s\tremaining: 9m 19s\n",
            "95:\tlearn: 0.7121550\ttotal: 59.2s\tremaining: 9m 17s\n",
            "96:\tlearn: 0.7120209\ttotal: 59.6s\tremaining: 9m 15s\n",
            "97:\tlearn: 0.7112768\ttotal: 1m\tremaining: 9m 13s\n",
            "98:\tlearn: 0.7091220\ttotal: 1m\tremaining: 9m 12s\n",
            "99:\tlearn: 0.7067532\ttotal: 1m 1s\tremaining: 9m 11s\n",
            "100:\tlearn: 0.7035783\ttotal: 1m 1s\tremaining: 9m 9s\n",
            "101:\tlearn: 0.7031042\ttotal: 1m 2s\tremaining: 9m 7s\n",
            "102:\tlearn: 0.7028231\ttotal: 1m 2s\tremaining: 9m 5s\n",
            "103:\tlearn: 0.6401723\ttotal: 1m 3s\tremaining: 9m 4s\n",
            "104:\tlearn: 0.6384606\ttotal: 1m 3s\tremaining: 9m 2s\n",
            "105:\tlearn: 0.6377116\ttotal: 1m 4s\tremaining: 9m\n",
            "106:\tlearn: 0.6360601\ttotal: 1m 4s\tremaining: 8m 59s\n",
            "107:\tlearn: 0.6346199\ttotal: 1m 5s\tremaining: 8m 58s\n",
            "108:\tlearn: 0.6332375\ttotal: 1m 5s\tremaining: 8m 56s\n",
            "109:\tlearn: 0.6328254\ttotal: 1m 6s\tremaining: 8m 56s\n",
            "110:\tlearn: 0.6175227\ttotal: 1m 7s\tremaining: 8m 58s\n",
            "111:\tlearn: 0.6150790\ttotal: 1m 8s\tremaining: 9m\n",
            "112:\tlearn: 0.6138176\ttotal: 1m 8s\tremaining: 8m 59s\n",
            "113:\tlearn: 0.6132688\ttotal: 1m 9s\tremaining: 8m 57s\n",
            "114:\tlearn: 0.6124724\ttotal: 1m 9s\tremaining: 8m 55s\n",
            "115:\tlearn: 0.6107207\ttotal: 1m 10s\tremaining: 8m 54s\n",
            "116:\tlearn: 0.6097106\ttotal: 1m 10s\tremaining: 8m 52s\n",
            "117:\tlearn: 0.6088499\ttotal: 1m 11s\tremaining: 8m 50s\n",
            "118:\tlearn: 0.6075048\ttotal: 1m 11s\tremaining: 8m 49s\n",
            "119:\tlearn: 0.6054985\ttotal: 1m 12s\tremaining: 8m 49s\n",
            "120:\tlearn: 0.6051328\ttotal: 1m 12s\tremaining: 8m 47s\n",
            "121:\tlearn: 0.6046974\ttotal: 1m 13s\tremaining: 8m 45s\n",
            "122:\tlearn: 0.6037300\ttotal: 1m 13s\tremaining: 8m 44s\n",
            "123:\tlearn: 0.6029071\ttotal: 1m 14s\tremaining: 8m 43s\n",
            "124:\tlearn: 0.6025807\ttotal: 1m 14s\tremaining: 8m 41s\n",
            "125:\tlearn: 0.6017296\ttotal: 1m 14s\tremaining: 8m 39s\n",
            "126:\tlearn: 0.6000627\ttotal: 1m 15s\tremaining: 8m 39s\n",
            "127:\tlearn: 0.5997943\ttotal: 1m 16s\tremaining: 8m 37s\n",
            "128:\tlearn: 0.5955031\ttotal: 1m 16s\tremaining: 8m 36s\n",
            "129:\tlearn: 0.5948328\ttotal: 1m 17s\tremaining: 8m 36s\n",
            "130:\tlearn: 0.5933587\ttotal: 1m 17s\tremaining: 8m 35s\n",
            "131:\tlearn: 0.5929540\ttotal: 1m 18s\tremaining: 8m 34s\n",
            "132:\tlearn: 0.5911980\ttotal: 1m 19s\tremaining: 8m 36s\n",
            "133:\tlearn: 0.5865672\ttotal: 1m 20s\tremaining: 8m 38s\n",
            "134:\tlearn: 0.5847598\ttotal: 1m 21s\tremaining: 8m 39s\n",
            "135:\tlearn: 0.5394284\ttotal: 1m 21s\tremaining: 8m 38s\n",
            "136:\tlearn: 0.5385548\ttotal: 1m 22s\tremaining: 8m 38s\n",
            "137:\tlearn: 0.5383013\ttotal: 1m 23s\tremaining: 8m 38s\n",
            "138:\tlearn: 0.5377317\ttotal: 1m 23s\tremaining: 8m 39s\n",
            "139:\tlearn: 0.5374963\ttotal: 1m 24s\tremaining: 8m 40s\n",
            "140:\tlearn: 0.5111086\ttotal: 1m 25s\tremaining: 8m 39s\n",
            "141:\tlearn: 0.5100434\ttotal: 1m 25s\tremaining: 8m 37s\n",
            "142:\tlearn: 0.5091563\ttotal: 1m 26s\tremaining: 8m 36s\n",
            "143:\tlearn: 0.5088584\ttotal: 1m 26s\tremaining: 8m 35s\n",
            "144:\tlearn: 0.5084684\ttotal: 1m 27s\tremaining: 8m 33s\n",
            "145:\tlearn: 0.5079767\ttotal: 1m 27s\tremaining: 8m 32s\n",
            "146:\tlearn: 0.5070820\ttotal: 1m 28s\tremaining: 8m 31s\n",
            "147:\tlearn: 0.5052056\ttotal: 1m 28s\tremaining: 8m 31s\n",
            "148:\tlearn: 0.5046739\ttotal: 1m 29s\tremaining: 8m 29s\n",
            "149:\tlearn: 0.5030080\ttotal: 1m 29s\tremaining: 8m 28s\n",
            "150:\tlearn: 0.5007763\ttotal: 1m 30s\tremaining: 8m 27s\n",
            "151:\tlearn: 0.5006952\ttotal: 1m 30s\tremaining: 8m 26s\n",
            "152:\tlearn: 0.5003618\ttotal: 1m 31s\tremaining: 8m 27s\n",
            "153:\tlearn: 0.4999946\ttotal: 1m 32s\tremaining: 8m 28s\n",
            "154:\tlearn: 0.4995759\ttotal: 1m 33s\tremaining: 8m 28s\n",
            "155:\tlearn: 0.4991512\ttotal: 1m 33s\tremaining: 8m 26s\n",
            "156:\tlearn: 0.4984362\ttotal: 1m 34s\tremaining: 8m 26s\n",
            "157:\tlearn: 0.4966723\ttotal: 1m 34s\tremaining: 8m 24s\n",
            "158:\tlearn: 0.4954714\ttotal: 1m 35s\tremaining: 8m 23s\n",
            "159:\tlearn: 0.4951638\ttotal: 1m 35s\tremaining: 8m 22s\n",
            "160:\tlearn: 0.4946126\ttotal: 1m 36s\tremaining: 8m 22s\n",
            "161:\tlearn: 0.4926592\ttotal: 1m 36s\tremaining: 8m 21s\n",
            "162:\tlearn: 0.4899290\ttotal: 1m 37s\tremaining: 8m 21s\n",
            "163:\tlearn: 0.4885998\ttotal: 1m 38s\tremaining: 8m 20s\n",
            "164:\tlearn: 0.4877668\ttotal: 1m 38s\tremaining: 8m 19s\n",
            "165:\tlearn: 0.4864386\ttotal: 1m 39s\tremaining: 8m 18s\n",
            "166:\tlearn: 0.4855334\ttotal: 1m 39s\tremaining: 8m 17s\n",
            "167:\tlearn: 0.4833128\ttotal: 1m 40s\tremaining: 8m 16s\n",
            "168:\tlearn: 0.4792126\ttotal: 1m 40s\tremaining: 8m 16s\n",
            "169:\tlearn: 0.4783585\ttotal: 1m 41s\tremaining: 8m 15s\n",
            "170:\tlearn: 0.4780148\ttotal: 1m 41s\tremaining: 8m 13s\n",
            "171:\tlearn: 0.4769707\ttotal: 1m 42s\tremaining: 8m 13s\n",
            "172:\tlearn: 0.4742763\ttotal: 1m 43s\tremaining: 8m 14s\n",
            "173:\tlearn: 0.4739161\ttotal: 1m 44s\tremaining: 8m 15s\n",
            "174:\tlearn: 0.4734194\ttotal: 1m 45s\tremaining: 8m 16s\n",
            "175:\tlearn: 0.4729515\ttotal: 1m 45s\tremaining: 8m 15s\n",
            "176:\tlearn: 0.4722882\ttotal: 1m 46s\tremaining: 8m 13s\n",
            "177:\tlearn: 0.4711156\ttotal: 1m 46s\tremaining: 8m 12s\n",
            "178:\tlearn: 0.4705989\ttotal: 1m 47s\tremaining: 8m 11s\n",
            "179:\tlearn: 0.4699907\ttotal: 1m 47s\tremaining: 8m 10s\n",
            "180:\tlearn: 0.4693870\ttotal: 1m 48s\tremaining: 8m 9s\n",
            "181:\tlearn: 0.4691890\ttotal: 1m 48s\tremaining: 8m 8s\n",
            "182:\tlearn: 0.4688783\ttotal: 1m 49s\tremaining: 8m 7s\n",
            "183:\tlearn: 0.4678803\ttotal: 1m 49s\tremaining: 8m 6s\n",
            "184:\tlearn: 0.4673047\ttotal: 1m 50s\tremaining: 8m 5s\n",
            "185:\tlearn: 0.4662859\ttotal: 1m 50s\tremaining: 8m 5s\n",
            "186:\tlearn: 0.4661160\ttotal: 1m 51s\tremaining: 8m 3s\n",
            "187:\tlearn: 0.4657850\ttotal: 1m 51s\tremaining: 8m 2s\n",
            "188:\tlearn: 0.4655042\ttotal: 1m 52s\tremaining: 8m 1s\n",
            "189:\tlearn: 0.4647095\ttotal: 1m 52s\tremaining: 8m\n",
            "190:\tlearn: 0.4601591\ttotal: 1m 53s\tremaining: 8m\n",
            "191:\tlearn: 0.4590071\ttotal: 1m 54s\tremaining: 7m 59s\n",
            "192:\tlearn: 0.4578727\ttotal: 1m 54s\tremaining: 7m 58s\n",
            "193:\tlearn: 0.4573491\ttotal: 1m 55s\tremaining: 7m 57s\n",
            "194:\tlearn: 0.4566208\ttotal: 1m 55s\tremaining: 7m 57s\n",
            "195:\tlearn: 0.4559166\ttotal: 1m 56s\tremaining: 7m 57s\n",
            "196:\tlearn: 0.4558581\ttotal: 1m 57s\tremaining: 7m 58s\n",
            "197:\tlearn: 0.4550189\ttotal: 1m 58s\tremaining: 7m 58s\n",
            "198:\tlearn: 0.4540726\ttotal: 1m 58s\tremaining: 7m 57s\n",
            "199:\tlearn: 0.4531053\ttotal: 1m 59s\tremaining: 7m 55s\n",
            "200:\tlearn: 0.4529678\ttotal: 1m 59s\tremaining: 7m 54s\n",
            "201:\tlearn: 0.4524284\ttotal: 2m\tremaining: 7m 54s\n",
            "202:\tlearn: 0.4519335\ttotal: 2m\tremaining: 7m 53s\n",
            "203:\tlearn: 0.4503901\ttotal: 2m 1s\tremaining: 7m 52s\n",
            "204:\tlearn: 0.4498167\ttotal: 2m 1s\tremaining: 7m 52s\n",
            "205:\tlearn: 0.4489990\ttotal: 2m 2s\tremaining: 7m 51s\n",
            "206:\tlearn: 0.4487412\ttotal: 2m 2s\tremaining: 7m 50s\n",
            "207:\tlearn: 0.4485706\ttotal: 2m 3s\tremaining: 7m 49s\n",
            "208:\tlearn: 0.4480778\ttotal: 2m 3s\tremaining: 7m 48s\n",
            "209:\tlearn: 0.4477218\ttotal: 2m 4s\tremaining: 7m 47s\n",
            "210:\tlearn: 0.4473050\ttotal: 2m 4s\tremaining: 7m 46s\n",
            "211:\tlearn: 0.4451366\ttotal: 2m 5s\tremaining: 7m 46s\n",
            "212:\tlearn: 0.4445778\ttotal: 2m 6s\tremaining: 7m 45s\n",
            "213:\tlearn: 0.4435648\ttotal: 2m 6s\tremaining: 7m 44s\n",
            "214:\tlearn: 0.4430715\ttotal: 2m 7s\tremaining: 7m 43s\n",
            "215:\tlearn: 0.4416762\ttotal: 2m 7s\tremaining: 7m 42s\n",
            "216:\tlearn: 0.4406454\ttotal: 2m 8s\tremaining: 7m 43s\n",
            "217:\tlearn: 0.4403589\ttotal: 2m 9s\tremaining: 7m 43s\n",
            "218:\tlearn: 0.4399083\ttotal: 2m 10s\tremaining: 7m 43s\n",
            "219:\tlearn: 0.4391482\ttotal: 2m 10s\tremaining: 7m 43s\n",
            "220:\tlearn: 0.4390443\ttotal: 2m 11s\tremaining: 7m 42s\n",
            "221:\tlearn: 0.4374955\ttotal: 2m 11s\tremaining: 7m 41s\n",
            "222:\tlearn: 0.4369318\ttotal: 2m 12s\tremaining: 7m 40s\n",
            "223:\tlearn: 0.4367448\ttotal: 2m 12s\tremaining: 7m 39s\n",
            "224:\tlearn: 0.4357735\ttotal: 2m 13s\tremaining: 7m 38s\n",
            "225:\tlearn: 0.4353693\ttotal: 2m 13s\tremaining: 7m 38s\n",
            "226:\tlearn: 0.4350357\ttotal: 2m 14s\tremaining: 7m 37s\n",
            "227:\tlearn: 0.4340586\ttotal: 2m 14s\tremaining: 7m 36s\n",
            "228:\tlearn: 0.4334417\ttotal: 2m 15s\tremaining: 7m 35s\n",
            "229:\tlearn: 0.4332812\ttotal: 2m 15s\tremaining: 7m 34s\n",
            "230:\tlearn: 0.4329552\ttotal: 2m 16s\tremaining: 7m 33s\n",
            "231:\tlearn: 0.4325750\ttotal: 2m 16s\tremaining: 7m 32s\n",
            "232:\tlearn: 0.4322090\ttotal: 2m 17s\tremaining: 7m 31s\n",
            "233:\tlearn: 0.4313094\ttotal: 2m 17s\tremaining: 7m 31s\n",
            "234:\tlearn: 0.4311641\ttotal: 2m 18s\tremaining: 7m 30s\n",
            "235:\tlearn: 0.4308832\ttotal: 2m 18s\tremaining: 7m 29s\n",
            "236:\tlearn: 0.4305727\ttotal: 2m 19s\tremaining: 7m 28s\n",
            "237:\tlearn: 0.4304657\ttotal: 2m 19s\tremaining: 7m 27s\n",
            "238:\tlearn: 0.4292767\ttotal: 2m 20s\tremaining: 7m 27s\n",
            "239:\tlearn: 0.4289725\ttotal: 2m 21s\tremaining: 7m 28s\n",
            "240:\tlearn: 0.4285168\ttotal: 2m 22s\tremaining: 7m 29s\n",
            "241:\tlearn: 0.4279621\ttotal: 2m 23s\tremaining: 7m 28s\n",
            "242:\tlearn: 0.4277520\ttotal: 2m 23s\tremaining: 7m 27s\n",
            "243:\tlearn: 0.4272143\ttotal: 2m 24s\tremaining: 7m 26s\n",
            "244:\tlearn: 0.4270961\ttotal: 2m 24s\tremaining: 7m 25s\n",
            "245:\tlearn: 0.4267062\ttotal: 2m 24s\tremaining: 7m 24s\n",
            "246:\tlearn: 0.4256741\ttotal: 2m 25s\tremaining: 7m 24s\n",
            "247:\tlearn: 0.4255393\ttotal: 2m 26s\tremaining: 7m 23s\n",
            "248:\tlearn: 0.4241940\ttotal: 2m 26s\tremaining: 7m 22s\n",
            "249:\tlearn: 0.4237499\ttotal: 2m 27s\tremaining: 7m 21s\n",
            "250:\tlearn: 0.4230988\ttotal: 2m 27s\tremaining: 7m 20s\n",
            "251:\tlearn: 0.4225713\ttotal: 2m 28s\tremaining: 7m 19s\n",
            "252:\tlearn: 0.4223559\ttotal: 2m 28s\tremaining: 7m 18s\n",
            "253:\tlearn: 0.4221807\ttotal: 2m 29s\tremaining: 7m 17s\n",
            "254:\tlearn: 0.4216788\ttotal: 2m 29s\tremaining: 7m 16s\n",
            "255:\tlearn: 0.4215842\ttotal: 2m 30s\tremaining: 7m 16s\n",
            "256:\tlearn: 0.4207630\ttotal: 2m 30s\tremaining: 7m 15s\n",
            "257:\tlearn: 0.4188318\ttotal: 2m 31s\tremaining: 7m 15s\n",
            "258:\tlearn: 0.4179679\ttotal: 2m 31s\tremaining: 7m 14s\n",
            "259:\tlearn: 0.4173162\ttotal: 2m 32s\tremaining: 7m 14s\n",
            "260:\tlearn: 0.4171439\ttotal: 2m 33s\tremaining: 7m 13s\n",
            "261:\tlearn: 0.4163971\ttotal: 2m 34s\tremaining: 7m 15s\n",
            "262:\tlearn: 0.4159671\ttotal: 2m 35s\tremaining: 7m 15s\n",
            "263:\tlearn: 0.4156899\ttotal: 2m 35s\tremaining: 7m 14s\n",
            "264:\tlearn: 0.4154479\ttotal: 2m 36s\tremaining: 7m 13s\n",
            "265:\tlearn: 0.4140569\ttotal: 2m 36s\tremaining: 7m 13s\n",
            "266:\tlearn: 0.4136929\ttotal: 2m 37s\tremaining: 7m 12s\n",
            "267:\tlearn: 0.4133273\ttotal: 2m 38s\tremaining: 7m 11s\n",
            "268:\tlearn: 0.4130036\ttotal: 2m 38s\tremaining: 7m 10s\n",
            "269:\tlearn: 0.4125964\ttotal: 2m 39s\tremaining: 7m 9s\n",
            "270:\tlearn: 0.4121402\ttotal: 2m 39s\tremaining: 7m 9s\n",
            "271:\tlearn: 0.4118230\ttotal: 2m 40s\tremaining: 7m 8s\n",
            "272:\tlearn: 0.4113080\ttotal: 2m 40s\tremaining: 7m 7s\n",
            "273:\tlearn: 0.4109189\ttotal: 2m 41s\tremaining: 7m 6s\n",
            "274:\tlearn: 0.4104051\ttotal: 2m 41s\tremaining: 7m 5s\n",
            "275:\tlearn: 0.4101639\ttotal: 2m 42s\tremaining: 7m 5s\n",
            "276:\tlearn: 0.4083629\ttotal: 2m 42s\tremaining: 7m 4s\n",
            "277:\tlearn: 0.4078314\ttotal: 2m 43s\tremaining: 7m 3s\n",
            "278:\tlearn: 0.4073838\ttotal: 2m 43s\tremaining: 7m 2s\n",
            "279:\tlearn: 0.4059655\ttotal: 2m 44s\tremaining: 7m 2s\n",
            "280:\tlearn: 0.4058434\ttotal: 2m 44s\tremaining: 7m 1s\n",
            "281:\tlearn: 0.4054807\ttotal: 2m 45s\tremaining: 7m\n",
            "282:\tlearn: 0.4051383\ttotal: 2m 46s\tremaining: 7m\n",
            "283:\tlearn: 0.4049254\ttotal: 2m 47s\tremaining: 7m 1s\n",
            "284:\tlearn: 0.4046765\ttotal: 2m 47s\tremaining: 7m\n",
            "285:\tlearn: 0.4044330\ttotal: 2m 48s\tremaining: 6m 59s\n",
            "286:\tlearn: 0.4040451\ttotal: 2m 48s\tremaining: 6m 58s\n",
            "287:\tlearn: 0.4034705\ttotal: 2m 48s\tremaining: 6m 57s\n",
            "288:\tlearn: 0.4027227\ttotal: 2m 49s\tremaining: 6m 57s\n",
            "289:\tlearn: 0.4021377\ttotal: 2m 50s\tremaining: 6m 56s\n",
            "290:\tlearn: 0.4014219\ttotal: 2m 50s\tremaining: 6m 56s\n",
            "291:\tlearn: 0.4003311\ttotal: 2m 51s\tremaining: 6m 55s\n",
            "292:\tlearn: 0.3999656\ttotal: 2m 51s\tremaining: 6m 54s\n",
            "293:\tlearn: 0.3989968\ttotal: 2m 52s\tremaining: 6m 53s\n",
            "294:\tlearn: 0.3983719\ttotal: 2m 52s\tremaining: 6m 53s\n",
            "295:\tlearn: 0.3976742\ttotal: 2m 53s\tremaining: 6m 52s\n",
            "296:\tlearn: 0.3974332\ttotal: 2m 53s\tremaining: 6m 51s\n",
            "297:\tlearn: 0.3972433\ttotal: 2m 54s\tremaining: 6m 50s\n",
            "298:\tlearn: 0.3970540\ttotal: 2m 54s\tremaining: 6m 49s\n",
            "299:\tlearn: 0.3967933\ttotal: 2m 55s\tremaining: 6m 48s\n",
            "300:\tlearn: 0.3963746\ttotal: 2m 55s\tremaining: 6m 48s\n",
            "301:\tlearn: 0.3961190\ttotal: 2m 56s\tremaining: 6m 47s\n",
            "302:\tlearn: 0.3960411\ttotal: 2m 56s\tremaining: 6m 46s\n",
            "303:\tlearn: 0.3951651\ttotal: 2m 57s\tremaining: 6m 45s\n",
            "304:\tlearn: 0.3948055\ttotal: 2m 58s\tremaining: 6m 46s\n",
            "305:\tlearn: 0.3946753\ttotal: 2m 59s\tremaining: 6m 46s\n",
            "306:\tlearn: 0.3938388\ttotal: 3m\tremaining: 6m 46s\n",
            "307:\tlearn: 0.3934941\ttotal: 3m\tremaining: 6m 45s\n",
            "308:\tlearn: 0.3932914\ttotal: 3m 1s\tremaining: 6m 44s\n",
            "309:\tlearn: 0.3927816\ttotal: 3m 1s\tremaining: 6m 44s\n",
            "310:\tlearn: 0.3924214\ttotal: 3m 2s\tremaining: 6m 43s\n",
            "311:\tlearn: 0.3917020\ttotal: 3m 2s\tremaining: 6m 42s\n",
            "312:\tlearn: 0.3914625\ttotal: 3m 2s\tremaining: 6m 41s\n",
            "313:\tlearn: 0.3908488\ttotal: 3m 3s\tremaining: 6m 41s\n",
            "314:\tlearn: 0.3907565\ttotal: 3m 4s\tremaining: 6m 40s\n",
            "315:\tlearn: 0.3904755\ttotal: 3m 4s\tremaining: 6m 39s\n",
            "316:\tlearn: 0.3898105\ttotal: 3m 5s\tremaining: 6m 38s\n",
            "317:\tlearn: 0.3893380\ttotal: 3m 5s\tremaining: 6m 38s\n",
            "318:\tlearn: 0.3891887\ttotal: 3m 6s\tremaining: 6m 37s\n",
            "319:\tlearn: 0.3888696\ttotal: 3m 6s\tremaining: 6m 36s\n",
            "320:\tlearn: 0.3880777\ttotal: 3m 7s\tremaining: 6m 35s\n",
            "321:\tlearn: 0.3874302\ttotal: 3m 7s\tremaining: 6m 34s\n",
            "322:\tlearn: 0.3871399\ttotal: 3m 8s\tremaining: 6m 34s\n",
            "323:\tlearn: 0.3870114\ttotal: 3m 8s\tremaining: 6m 33s\n",
            "324:\tlearn: 0.3863718\ttotal: 3m 9s\tremaining: 6m 32s\n",
            "325:\tlearn: 0.3854530\ttotal: 3m 9s\tremaining: 6m 31s\n",
            "326:\tlearn: 0.3853614\ttotal: 3m 10s\tremaining: 6m 31s\n",
            "327:\tlearn: 0.3852610\ttotal: 3m 11s\tremaining: 6m 31s\n",
            "328:\tlearn: 0.3847974\ttotal: 3m 12s\tremaining: 6m 31s\n",
            "329:\tlearn: 0.3842302\ttotal: 3m 12s\tremaining: 6m 30s\n",
            "330:\tlearn: 0.3834028\ttotal: 3m 13s\tremaining: 6m 30s\n",
            "331:\tlearn: 0.3783890\ttotal: 3m 13s\tremaining: 6m 30s\n",
            "332:\tlearn: 0.3775303\ttotal: 3m 14s\tremaining: 6m 29s\n",
            "333:\tlearn: 0.3772499\ttotal: 3m 15s\tremaining: 6m 29s\n",
            "334:\tlearn: 0.3769974\ttotal: 3m 15s\tremaining: 6m 28s\n",
            "335:\tlearn: 0.3757906\ttotal: 3m 16s\tremaining: 6m 27s\n",
            "336:\tlearn: 0.3754324\ttotal: 3m 16s\tremaining: 6m 26s\n",
            "337:\tlearn: 0.3747627\ttotal: 3m 17s\tremaining: 6m 26s\n",
            "338:\tlearn: 0.3741200\ttotal: 3m 17s\tremaining: 6m 25s\n",
            "339:\tlearn: 0.3738797\ttotal: 3m 18s\tremaining: 6m 25s\n",
            "340:\tlearn: 0.3734619\ttotal: 3m 18s\tremaining: 6m 24s\n",
            "341:\tlearn: 0.3733398\ttotal: 3m 19s\tremaining: 6m 23s\n",
            "342:\tlearn: 0.3732016\ttotal: 3m 19s\tremaining: 6m 22s\n",
            "343:\tlearn: 0.3731145\ttotal: 3m 20s\tremaining: 6m 21s\n",
            "344:\tlearn: 0.3722863\ttotal: 3m 20s\tremaining: 6m 21s\n",
            "345:\tlearn: 0.3721335\ttotal: 3m 21s\tremaining: 6m 20s\n",
            "346:\tlearn: 0.3720833\ttotal: 3m 21s\tremaining: 6m 19s\n",
            "347:\tlearn: 0.3718443\ttotal: 3m 22s\tremaining: 6m 19s\n",
            "348:\tlearn: 0.3715394\ttotal: 3m 23s\tremaining: 6m 19s\n",
            "349:\tlearn: 0.3713412\ttotal: 3m 24s\tremaining: 6m 19s\n",
            "350:\tlearn: 0.3709761\ttotal: 3m 25s\tremaining: 6m 19s\n",
            "351:\tlearn: 0.3706278\ttotal: 3m 25s\tremaining: 6m 18s\n",
            "352:\tlearn: 0.3704965\ttotal: 3m 26s\tremaining: 6m 17s\n",
            "353:\tlearn: 0.3703332\ttotal: 3m 26s\tremaining: 6m 16s\n",
            "354:\tlearn: 0.3697088\ttotal: 3m 27s\tremaining: 6m 16s\n",
            "355:\tlearn: 0.3689779\ttotal: 3m 27s\tremaining: 6m 15s\n",
            "356:\tlearn: 0.3688542\ttotal: 3m 28s\tremaining: 6m 14s\n",
            "357:\tlearn: 0.3686216\ttotal: 3m 28s\tremaining: 6m 14s\n",
            "358:\tlearn: 0.3684719\ttotal: 3m 29s\tremaining: 6m 13s\n",
            "359:\tlearn: 0.3681891\ttotal: 3m 29s\tremaining: 6m 12s\n",
            "360:\tlearn: 0.3670249\ttotal: 3m 30s\tremaining: 6m 12s\n",
            "361:\tlearn: 0.3667360\ttotal: 3m 30s\tremaining: 6m 11s\n",
            "362:\tlearn: 0.3665426\ttotal: 3m 31s\tremaining: 6m 10s\n",
            "363:\tlearn: 0.3658986\ttotal: 3m 31s\tremaining: 6m 10s\n",
            "364:\tlearn: 0.3656797\ttotal: 3m 32s\tremaining: 6m 9s\n",
            "365:\tlearn: 0.3645619\ttotal: 3m 32s\tremaining: 6m 8s\n",
            "366:\tlearn: 0.3643721\ttotal: 3m 33s\tremaining: 6m 7s\n",
            "367:\tlearn: 0.3640280\ttotal: 3m 33s\tremaining: 6m 7s\n",
            "368:\tlearn: 0.3636209\ttotal: 3m 34s\tremaining: 6m 6s\n",
            "369:\tlearn: 0.3626283\ttotal: 3m 34s\tremaining: 6m 5s\n",
            "370:\tlearn: 0.3622031\ttotal: 3m 35s\tremaining: 6m 5s\n",
            "371:\tlearn: 0.3620296\ttotal: 3m 36s\tremaining: 6m 5s\n",
            "372:\tlearn: 0.3616988\ttotal: 3m 37s\tremaining: 6m 5s\n",
            "373:\tlearn: 0.3607273\ttotal: 3m 37s\tremaining: 6m 4s\n",
            "374:\tlearn: 0.3602959\ttotal: 3m 38s\tremaining: 6m 3s\n",
            "375:\tlearn: 0.3602099\ttotal: 3m 38s\tremaining: 6m 2s\n",
            "376:\tlearn: 0.3601114\ttotal: 3m 39s\tremaining: 6m 2s\n",
            "377:\tlearn: 0.3599122\ttotal: 3m 39s\tremaining: 6m 1s\n",
            "378:\tlearn: 0.3588814\ttotal: 3m 40s\tremaining: 6m\n",
            "379:\tlearn: 0.3587657\ttotal: 3m 40s\tremaining: 6m\n",
            "380:\tlearn: 0.3583182\ttotal: 3m 41s\tremaining: 5m 59s\n",
            "381:\tlearn: 0.3580330\ttotal: 3m 41s\tremaining: 5m 58s\n",
            "382:\tlearn: 0.3578627\ttotal: 3m 42s\tremaining: 5m 57s\n",
            "383:\tlearn: 0.3572796\ttotal: 3m 42s\tremaining: 5m 57s\n",
            "384:\tlearn: 0.3563044\ttotal: 3m 43s\tremaining: 5m 56s\n",
            "385:\tlearn: 0.3559817\ttotal: 3m 43s\tremaining: 5m 55s\n",
            "386:\tlearn: 0.3552678\ttotal: 3m 44s\tremaining: 5m 55s\n",
            "387:\tlearn: 0.3551052\ttotal: 3m 44s\tremaining: 5m 54s\n",
            "388:\tlearn: 0.3547426\ttotal: 3m 45s\tremaining: 5m 53s\n",
            "389:\tlearn: 0.3545116\ttotal: 3m 45s\tremaining: 5m 52s\n",
            "390:\tlearn: 0.3543446\ttotal: 3m 46s\tremaining: 5m 52s\n",
            "391:\tlearn: 0.3541921\ttotal: 3m 46s\tremaining: 5m 51s\n",
            "392:\tlearn: 0.3536476\ttotal: 3m 47s\tremaining: 5m 51s\n",
            "393:\tlearn: 0.3534392\ttotal: 3m 48s\tremaining: 5m 50s\n",
            "394:\tlearn: 0.3531558\ttotal: 3m 49s\tremaining: 5m 50s\n",
            "395:\tlearn: 0.3529643\ttotal: 3m 49s\tremaining: 5m 50s\n",
            "396:\tlearn: 0.3524874\ttotal: 3m 50s\tremaining: 5m 49s\n",
            "397:\tlearn: 0.3522442\ttotal: 3m 50s\tremaining: 5m 48s\n",
            "398:\tlearn: 0.3513145\ttotal: 3m 51s\tremaining: 5m 48s\n",
            "399:\tlearn: 0.3506687\ttotal: 3m 51s\tremaining: 5m 47s\n",
            "400:\tlearn: 0.3503195\ttotal: 3m 52s\tremaining: 5m 46s\n",
            "401:\tlearn: 0.3490993\ttotal: 3m 52s\tremaining: 5m 46s\n",
            "402:\tlearn: 0.3489570\ttotal: 3m 53s\tremaining: 5m 45s\n",
            "403:\tlearn: 0.3488043\ttotal: 3m 53s\tremaining: 5m 44s\n",
            "404:\tlearn: 0.3479358\ttotal: 3m 54s\tremaining: 5m 44s\n",
            "405:\tlearn: 0.3474283\ttotal: 3m 54s\tremaining: 5m 43s\n",
            "406:\tlearn: 0.3471267\ttotal: 3m 55s\tremaining: 5m 42s\n",
            "407:\tlearn: 0.3466779\ttotal: 3m 55s\tremaining: 5m 42s\n",
            "408:\tlearn: 0.3464666\ttotal: 3m 56s\tremaining: 5m 41s\n",
            "409:\tlearn: 0.3457121\ttotal: 3m 56s\tremaining: 5m 40s\n",
            "410:\tlearn: 0.3455640\ttotal: 3m 57s\tremaining: 5m 40s\n",
            "411:\tlearn: 0.3453537\ttotal: 3m 57s\tremaining: 5m 39s\n",
            "412:\tlearn: 0.3451973\ttotal: 3m 58s\tremaining: 5m 38s\n",
            "413:\tlearn: 0.3450519\ttotal: 3m 58s\tremaining: 5m 37s\n",
            "414:\tlearn: 0.3445456\ttotal: 3m 59s\tremaining: 5m 37s\n",
            "415:\tlearn: 0.3435009\ttotal: 4m\tremaining: 5m 37s\n",
            "416:\tlearn: 0.3433927\ttotal: 4m 1s\tremaining: 5m 37s\n",
            "417:\tlearn: 0.3431891\ttotal: 4m 1s\tremaining: 5m 36s\n",
            "418:\tlearn: 0.3426422\ttotal: 4m 2s\tremaining: 5m 36s\n",
            "419:\tlearn: 0.3423737\ttotal: 4m 2s\tremaining: 5m 35s\n",
            "420:\tlearn: 0.3413799\ttotal: 4m 3s\tremaining: 5m 34s\n",
            "421:\tlearn: 0.3410012\ttotal: 4m 4s\tremaining: 5m 34s\n",
            "422:\tlearn: 0.3408988\ttotal: 4m 4s\tremaining: 5m 33s\n",
            "423:\tlearn: 0.3404484\ttotal: 4m 4s\tremaining: 5m 32s\n",
            "424:\tlearn: 0.3402029\ttotal: 4m 5s\tremaining: 5m 32s\n",
            "425:\tlearn: 0.3399976\ttotal: 4m 5s\tremaining: 5m 31s\n",
            "426:\tlearn: 0.3398457\ttotal: 4m 6s\tremaining: 5m 30s\n",
            "427:\tlearn: 0.3391536\ttotal: 4m 6s\tremaining: 5m 30s\n",
            "428:\tlearn: 0.3386473\ttotal: 4m 7s\tremaining: 5m 29s\n",
            "429:\tlearn: 0.3383651\ttotal: 4m 8s\tremaining: 5m 29s\n",
            "430:\tlearn: 0.3379326\ttotal: 4m 8s\tremaining: 5m 28s\n",
            "431:\tlearn: 0.3376712\ttotal: 4m 9s\tremaining: 5m 27s\n",
            "432:\tlearn: 0.3373194\ttotal: 4m 9s\tremaining: 5m 27s\n",
            "433:\tlearn: 0.3368509\ttotal: 4m 10s\tremaining: 5m 26s\n",
            "434:\tlearn: 0.3361126\ttotal: 4m 10s\tremaining: 5m 25s\n",
            "435:\tlearn: 0.3360203\ttotal: 4m 11s\tremaining: 5m 25s\n",
            "436:\tlearn: 0.3347836\ttotal: 4m 12s\tremaining: 5m 24s\n",
            "437:\tlearn: 0.3346092\ttotal: 4m 12s\tremaining: 5m 24s\n",
            "438:\tlearn: 0.3342232\ttotal: 4m 13s\tremaining: 5m 24s\n",
            "439:\tlearn: 0.3339975\ttotal: 4m 14s\tremaining: 5m 23s\n",
            "440:\tlearn: 0.3336476\ttotal: 4m 14s\tremaining: 5m 23s\n",
            "441:\tlearn: 0.3335004\ttotal: 4m 15s\tremaining: 5m 22s\n",
            "442:\tlearn: 0.3332862\ttotal: 4m 16s\tremaining: 5m 21s\n",
            "443:\tlearn: 0.3331499\ttotal: 4m 16s\tremaining: 5m 21s\n",
            "444:\tlearn: 0.3328576\ttotal: 4m 16s\tremaining: 5m 20s\n",
            "445:\tlearn: 0.3324080\ttotal: 4m 17s\tremaining: 5m 19s\n",
            "446:\tlearn: 0.3311085\ttotal: 4m 18s\tremaining: 5m 19s\n",
            "447:\tlearn: 0.3306989\ttotal: 4m 18s\tremaining: 5m 18s\n",
            "448:\tlearn: 0.3303089\ttotal: 4m 19s\tremaining: 5m 17s\n",
            "449:\tlearn: 0.3301062\ttotal: 4m 19s\tremaining: 5m 17s\n",
            "450:\tlearn: 0.3294656\ttotal: 4m 19s\tremaining: 5m 16s\n",
            "451:\tlearn: 0.3284066\ttotal: 4m 20s\tremaining: 5m 15s\n",
            "452:\tlearn: 0.3280303\ttotal: 4m 21s\tremaining: 5m 15s\n",
            "453:\tlearn: 0.3276082\ttotal: 4m 21s\tremaining: 5m 14s\n",
            "454:\tlearn: 0.3272734\ttotal: 4m 22s\tremaining: 5m 13s\n",
            "455:\tlearn: 0.3267581\ttotal: 4m 22s\tremaining: 5m 13s\n",
            "456:\tlearn: 0.3265915\ttotal: 4m 23s\tremaining: 5m 12s\n",
            "457:\tlearn: 0.3263155\ttotal: 4m 23s\tremaining: 5m 12s\n",
            "458:\tlearn: 0.3260589\ttotal: 4m 24s\tremaining: 5m 11s\n",
            "459:\tlearn: 0.3254793\ttotal: 4m 25s\tremaining: 5m 11s\n",
            "460:\tlearn: 0.3239082\ttotal: 4m 26s\tremaining: 5m 11s\n",
            "461:\tlearn: 0.3236145\ttotal: 4m 26s\tremaining: 5m 10s\n",
            "462:\tlearn: 0.3233670\ttotal: 4m 27s\tremaining: 5m 9s\n",
            "463:\tlearn: 0.3230494\ttotal: 4m 27s\tremaining: 5m 9s\n",
            "464:\tlearn: 0.3228875\ttotal: 4m 28s\tremaining: 5m 8s\n",
            "465:\tlearn: 0.3228649\ttotal: 4m 28s\tremaining: 5m 8s\n",
            "466:\tlearn: 0.3222416\ttotal: 4m 29s\tremaining: 5m 7s\n",
            "467:\tlearn: 0.3220060\ttotal: 4m 29s\tremaining: 5m 6s\n",
            "468:\tlearn: 0.3214805\ttotal: 4m 30s\tremaining: 5m 6s\n",
            "469:\tlearn: 0.3212298\ttotal: 4m 30s\tremaining: 5m 5s\n",
            "470:\tlearn: 0.3211438\ttotal: 4m 31s\tremaining: 5m 4s\n",
            "471:\tlearn: 0.3207513\ttotal: 4m 31s\tremaining: 5m 3s\n",
            "472:\tlearn: 0.3206000\ttotal: 4m 32s\tremaining: 5m 3s\n",
            "473:\tlearn: 0.3201961\ttotal: 4m 32s\tremaining: 5m 2s\n",
            "474:\tlearn: 0.3200121\ttotal: 4m 33s\tremaining: 5m 2s\n",
            "475:\tlearn: 0.3197227\ttotal: 4m 34s\tremaining: 5m 1s\n",
            "476:\tlearn: 0.3195574\ttotal: 4m 34s\tremaining: 5m\n",
            "477:\tlearn: 0.3194168\ttotal: 4m 34s\tremaining: 5m\n",
            "478:\tlearn: 0.3192732\ttotal: 4m 35s\tremaining: 4m 59s\n",
            "479:\tlearn: 0.3191798\ttotal: 4m 35s\tremaining: 4m 58s\n",
            "480:\tlearn: 0.3185823\ttotal: 4m 36s\tremaining: 4m 58s\n",
            "481:\tlearn: 0.3182133\ttotal: 4m 37s\tremaining: 4m 58s\n",
            "482:\tlearn: 0.3180250\ttotal: 4m 38s\tremaining: 4m 58s\n",
            "483:\tlearn: 0.3172960\ttotal: 4m 39s\tremaining: 4m 58s\n",
            "484:\tlearn: 0.3163939\ttotal: 4m 40s\tremaining: 4m 58s\n",
            "485:\tlearn: 0.3162385\ttotal: 4m 41s\tremaining: 4m 57s\n",
            "486:\tlearn: 0.3151759\ttotal: 4m 42s\tremaining: 4m 57s\n",
            "487:\tlearn: 0.3151432\ttotal: 4m 42s\tremaining: 4m 56s\n",
            "488:\tlearn: 0.3149894\ttotal: 4m 43s\tremaining: 4m 55s\n",
            "489:\tlearn: 0.3148784\ttotal: 4m 43s\tremaining: 4m 55s\n",
            "490:\tlearn: 0.3147731\ttotal: 4m 43s\tremaining: 4m 54s\n",
            "491:\tlearn: 0.3142927\ttotal: 4m 44s\tremaining: 4m 53s\n",
            "492:\tlearn: 0.3141435\ttotal: 4m 45s\tremaining: 4m 53s\n",
            "493:\tlearn: 0.3137651\ttotal: 4m 45s\tremaining: 4m 52s\n",
            "494:\tlearn: 0.3135670\ttotal: 4m 45s\tremaining: 4m 51s\n",
            "495:\tlearn: 0.3134191\ttotal: 4m 46s\tremaining: 4m 51s\n",
            "496:\tlearn: 0.3131474\ttotal: 4m 46s\tremaining: 4m 50s\n",
            "497:\tlearn: 0.3123607\ttotal: 4m 47s\tremaining: 4m 49s\n",
            "498:\tlearn: 0.3123189\ttotal: 4m 48s\tremaining: 4m 49s\n",
            "499:\tlearn: 0.3118194\ttotal: 4m 48s\tremaining: 4m 48s\n",
            "500:\tlearn: 0.3113072\ttotal: 4m 48s\tremaining: 4m 47s\n",
            "501:\tlearn: 0.3111801\ttotal: 4m 49s\tremaining: 4m 47s\n",
            "502:\tlearn: 0.3110288\ttotal: 4m 49s\tremaining: 4m 46s\n",
            "503:\tlearn: 0.3103686\ttotal: 4m 50s\tremaining: 4m 45s\n",
            "504:\tlearn: 0.3099959\ttotal: 4m 51s\tremaining: 4m 45s\n",
            "505:\tlearn: 0.3092460\ttotal: 4m 52s\tremaining: 4m 45s\n",
            "506:\tlearn: 0.3090462\ttotal: 4m 53s\tremaining: 4m 45s\n",
            "507:\tlearn: 0.3089975\ttotal: 4m 53s\tremaining: 4m 44s\n",
            "508:\tlearn: 0.3087517\ttotal: 4m 54s\tremaining: 4m 43s\n",
            "509:\tlearn: 0.3085174\ttotal: 4m 54s\tremaining: 4m 43s\n",
            "510:\tlearn: 0.3082109\ttotal: 4m 55s\tremaining: 4m 42s\n",
            "511:\tlearn: 0.3071007\ttotal: 4m 55s\tremaining: 4m 41s\n",
            "512:\tlearn: 0.3067489\ttotal: 4m 56s\tremaining: 4m 41s\n",
            "513:\tlearn: 0.3064315\ttotal: 4m 56s\tremaining: 4m 40s\n",
            "514:\tlearn: 0.3056449\ttotal: 4m 57s\tremaining: 4m 39s\n",
            "515:\tlearn: 0.3052363\ttotal: 4m 57s\tremaining: 4m 39s\n",
            "516:\tlearn: 0.3049985\ttotal: 4m 58s\tremaining: 4m 38s\n",
            "517:\tlearn: 0.3048714\ttotal: 4m 58s\tremaining: 4m 37s\n",
            "518:\tlearn: 0.3047376\ttotal: 4m 59s\tremaining: 4m 37s\n",
            "519:\tlearn: 0.3045865\ttotal: 4m 59s\tremaining: 4m 36s\n",
            "520:\tlearn: 0.3043229\ttotal: 5m\tremaining: 4m 35s\n",
            "521:\tlearn: 0.3037532\ttotal: 5m\tremaining: 4m 35s\n",
            "522:\tlearn: 0.3029442\ttotal: 5m 1s\tremaining: 4m 34s\n",
            "523:\tlearn: 0.3026779\ttotal: 5m 1s\tremaining: 4m 34s\n",
            "524:\tlearn: 0.3025326\ttotal: 5m 2s\tremaining: 4m 33s\n",
            "525:\tlearn: 0.3024441\ttotal: 5m 2s\tremaining: 4m 32s\n",
            "526:\tlearn: 0.3021390\ttotal: 5m 3s\tremaining: 4m 32s\n",
            "527:\tlearn: 0.3019975\ttotal: 5m 4s\tremaining: 4m 32s\n",
            "528:\tlearn: 0.3017247\ttotal: 5m 5s\tremaining: 4m 32s\n",
            "529:\tlearn: 0.3015615\ttotal: 5m 6s\tremaining: 4m 31s\n",
            "530:\tlearn: 0.3013578\ttotal: 5m 6s\tremaining: 4m 30s\n",
            "531:\tlearn: 0.3009005\ttotal: 5m 7s\tremaining: 4m 30s\n",
            "532:\tlearn: 0.3007229\ttotal: 5m 7s\tremaining: 4m 29s\n",
            "533:\tlearn: 0.2999692\ttotal: 5m 8s\tremaining: 4m 29s\n",
            "534:\tlearn: 0.2979545\ttotal: 5m 8s\tremaining: 4m 28s\n",
            "535:\tlearn: 0.2977979\ttotal: 5m 9s\tremaining: 4m 27s\n",
            "536:\tlearn: 0.2973094\ttotal: 5m 9s\tremaining: 4m 27s\n",
            "537:\tlearn: 0.2969064\ttotal: 5m 10s\tremaining: 4m 26s\n",
            "538:\tlearn: 0.2966433\ttotal: 5m 10s\tremaining: 4m 25s\n",
            "539:\tlearn: 0.2957527\ttotal: 5m 11s\tremaining: 4m 25s\n",
            "540:\tlearn: 0.2951325\ttotal: 5m 11s\tremaining: 4m 24s\n",
            "541:\tlearn: 0.2944130\ttotal: 5m 12s\tremaining: 4m 24s\n",
            "542:\tlearn: 0.2942815\ttotal: 5m 12s\tremaining: 4m 23s\n",
            "543:\tlearn: 0.2940142\ttotal: 5m 13s\tremaining: 4m 22s\n",
            "544:\tlearn: 0.2933467\ttotal: 5m 14s\tremaining: 4m 22s\n",
            "545:\tlearn: 0.2928493\ttotal: 5m 14s\tremaining: 4m 21s\n",
            "546:\tlearn: 0.2924376\ttotal: 5m 15s\tremaining: 4m 21s\n",
            "547:\tlearn: 0.2922251\ttotal: 5m 15s\tremaining: 4m 20s\n",
            "548:\tlearn: 0.2919399\ttotal: 5m 16s\tremaining: 4m 20s\n",
            "549:\tlearn: 0.2917896\ttotal: 5m 17s\tremaining: 4m 19s\n",
            "550:\tlearn: 0.2916999\ttotal: 5m 18s\tremaining: 4m 19s\n",
            "551:\tlearn: 0.2913005\ttotal: 5m 18s\tremaining: 4m 18s\n",
            "552:\tlearn: 0.2910274\ttotal: 5m 19s\tremaining: 4m 18s\n",
            "553:\tlearn: 0.2894698\ttotal: 5m 19s\tremaining: 4m 17s\n",
            "554:\tlearn: 0.2893462\ttotal: 5m 20s\tremaining: 4m 16s\n",
            "555:\tlearn: 0.2891376\ttotal: 5m 20s\tremaining: 4m 16s\n",
            "556:\tlearn: 0.2889129\ttotal: 5m 21s\tremaining: 4m 15s\n",
            "557:\tlearn: 0.2887136\ttotal: 5m 21s\tremaining: 4m 14s\n",
            "558:\tlearn: 0.2886184\ttotal: 5m 22s\tremaining: 4m 14s\n",
            "559:\tlearn: 0.2876730\ttotal: 5m 22s\tremaining: 4m 13s\n",
            "560:\tlearn: 0.2872874\ttotal: 5m 23s\tremaining: 4m 12s\n",
            "561:\tlearn: 0.2872216\ttotal: 5m 23s\tremaining: 4m 12s\n",
            "562:\tlearn: 0.2867753\ttotal: 5m 24s\tremaining: 4m 11s\n",
            "563:\tlearn: 0.2854141\ttotal: 5m 24s\tremaining: 4m 11s\n",
            "564:\tlearn: 0.2850964\ttotal: 5m 25s\tremaining: 4m 10s\n",
            "565:\tlearn: 0.2846926\ttotal: 5m 25s\tremaining: 4m 9s\n",
            "566:\tlearn: 0.2840878\ttotal: 5m 26s\tremaining: 4m 9s\n",
            "567:\tlearn: 0.2838335\ttotal: 5m 27s\tremaining: 4m 8s\n",
            "568:\tlearn: 0.2836652\ttotal: 5m 27s\tremaining: 4m 8s\n",
            "569:\tlearn: 0.2832497\ttotal: 5m 28s\tremaining: 4m 7s\n",
            "570:\tlearn: 0.2829942\ttotal: 5m 29s\tremaining: 4m 7s\n",
            "571:\tlearn: 0.2825863\ttotal: 5m 30s\tremaining: 4m 7s\n",
            "572:\tlearn: 0.2819559\ttotal: 5m 31s\tremaining: 4m 6s\n",
            "573:\tlearn: 0.2815793\ttotal: 5m 31s\tremaining: 4m 6s\n",
            "574:\tlearn: 0.2813433\ttotal: 5m 32s\tremaining: 4m 5s\n",
            "575:\tlearn: 0.2810978\ttotal: 5m 32s\tremaining: 4m 4s\n",
            "576:\tlearn: 0.2808926\ttotal: 5m 33s\tremaining: 4m 4s\n",
            "577:\tlearn: 0.2807176\ttotal: 5m 33s\tremaining: 4m 3s\n",
            "578:\tlearn: 0.2803246\ttotal: 5m 34s\tremaining: 4m 2s\n",
            "579:\tlearn: 0.2799529\ttotal: 5m 34s\tremaining: 4m 2s\n",
            "580:\tlearn: 0.2796642\ttotal: 5m 35s\tremaining: 4m 1s\n",
            "581:\tlearn: 0.2795605\ttotal: 5m 35s\tremaining: 4m 1s\n",
            "582:\tlearn: 0.2794301\ttotal: 5m 36s\tremaining: 4m\n",
            "583:\tlearn: 0.2789814\ttotal: 5m 36s\tremaining: 3m 59s\n",
            "584:\tlearn: 0.2788269\ttotal: 5m 36s\tremaining: 3m 59s\n",
            "585:\tlearn: 0.2784647\ttotal: 5m 37s\tremaining: 3m 58s\n",
            "586:\tlearn: 0.2779738\ttotal: 5m 38s\tremaining: 3m 57s\n",
            "587:\tlearn: 0.2771456\ttotal: 5m 38s\tremaining: 3m 57s\n",
            "588:\tlearn: 0.2769344\ttotal: 5m 39s\tremaining: 3m 56s\n",
            "589:\tlearn: 0.2767968\ttotal: 5m 39s\tremaining: 3m 56s\n",
            "590:\tlearn: 0.2760111\ttotal: 5m 40s\tremaining: 3m 55s\n",
            "591:\tlearn: 0.2757712\ttotal: 5m 41s\tremaining: 3m 55s\n",
            "592:\tlearn: 0.2756720\ttotal: 5m 42s\tremaining: 3m 54s\n",
            "593:\tlearn: 0.2753950\ttotal: 5m 42s\tremaining: 3m 54s\n",
            "594:\tlearn: 0.2745263\ttotal: 5m 43s\tremaining: 3m 53s\n",
            "595:\tlearn: 0.2743775\ttotal: 5m 44s\tremaining: 3m 53s\n",
            "596:\tlearn: 0.2742196\ttotal: 5m 44s\tremaining: 3m 52s\n",
            "597:\tlearn: 0.2741267\ttotal: 5m 45s\tremaining: 3m 52s\n",
            "598:\tlearn: 0.2736989\ttotal: 5m 45s\tremaining: 3m 51s\n",
            "599:\tlearn: 0.2734382\ttotal: 5m 46s\tremaining: 3m 50s\n",
            "600:\tlearn: 0.2732253\ttotal: 5m 46s\tremaining: 3m 50s\n",
            "601:\tlearn: 0.2731055\ttotal: 5m 47s\tremaining: 3m 49s\n",
            "602:\tlearn: 0.2724319\ttotal: 5m 48s\tremaining: 3m 49s\n",
            "603:\tlearn: 0.2720379\ttotal: 5m 48s\tremaining: 3m 48s\n",
            "604:\tlearn: 0.2715489\ttotal: 5m 49s\tremaining: 3m 48s\n",
            "605:\tlearn: 0.2713516\ttotal: 5m 49s\tremaining: 3m 47s\n",
            "606:\tlearn: 0.2708300\ttotal: 5m 50s\tremaining: 3m 46s\n",
            "607:\tlearn: 0.2705623\ttotal: 5m 50s\tremaining: 3m 46s\n",
            "608:\tlearn: 0.2703011\ttotal: 5m 51s\tremaining: 3m 45s\n",
            "609:\tlearn: 0.2699325\ttotal: 5m 51s\tremaining: 3m 45s\n",
            "610:\tlearn: 0.2697057\ttotal: 5m 52s\tremaining: 3m 44s\n",
            "611:\tlearn: 0.2691791\ttotal: 5m 53s\tremaining: 3m 44s\n",
            "612:\tlearn: 0.2688906\ttotal: 5m 54s\tremaining: 3m 43s\n",
            "613:\tlearn: 0.2687183\ttotal: 5m 55s\tremaining: 3m 43s\n",
            "614:\tlearn: 0.2683618\ttotal: 5m 55s\tremaining: 3m 42s\n",
            "615:\tlearn: 0.2676541\ttotal: 5m 56s\tremaining: 3m 42s\n",
            "616:\tlearn: 0.2675054\ttotal: 5m 56s\tremaining: 3m 41s\n",
            "617:\tlearn: 0.2672219\ttotal: 5m 57s\tremaining: 3m 40s\n",
            "618:\tlearn: 0.2668973\ttotal: 5m 57s\tremaining: 3m 40s\n",
            "619:\tlearn: 0.2664605\ttotal: 5m 58s\tremaining: 3m 39s\n",
            "620:\tlearn: 0.2663788\ttotal: 5m 58s\tremaining: 3m 38s\n",
            "621:\tlearn: 0.2658471\ttotal: 5m 59s\tremaining: 3m 38s\n",
            "622:\tlearn: 0.2657294\ttotal: 5m 59s\tremaining: 3m 37s\n",
            "623:\tlearn: 0.2655875\ttotal: 6m\tremaining: 3m 37s\n",
            "624:\tlearn: 0.2652955\ttotal: 6m\tremaining: 3m 36s\n",
            "625:\tlearn: 0.2651769\ttotal: 6m 1s\tremaining: 3m 35s\n",
            "626:\tlearn: 0.2648683\ttotal: 6m 1s\tremaining: 3m 35s\n",
            "627:\tlearn: 0.2646816\ttotal: 6m 2s\tremaining: 3m 34s\n",
            "628:\tlearn: 0.2644599\ttotal: 6m 2s\tremaining: 3m 33s\n",
            "629:\tlearn: 0.2643262\ttotal: 6m 3s\tremaining: 3m 33s\n",
            "630:\tlearn: 0.2639787\ttotal: 6m 3s\tremaining: 3m 32s\n",
            "631:\tlearn: 0.2637568\ttotal: 6m 4s\tremaining: 3m 32s\n",
            "632:\tlearn: 0.2635963\ttotal: 6m 4s\tremaining: 3m 31s\n",
            "633:\tlearn: 0.2630705\ttotal: 6m 5s\tremaining: 3m 30s\n",
            "634:\tlearn: 0.2626012\ttotal: 6m 6s\tremaining: 3m 30s\n",
            "635:\tlearn: 0.2625137\ttotal: 6m 7s\tremaining: 3m 30s\n",
            "636:\tlearn: 0.2618707\ttotal: 6m 7s\tremaining: 3m 29s\n",
            "637:\tlearn: 0.2616666\ttotal: 6m 8s\tremaining: 3m 29s\n",
            "638:\tlearn: 0.2614185\ttotal: 6m 9s\tremaining: 3m 28s\n",
            "639:\tlearn: 0.2613064\ttotal: 6m 9s\tremaining: 3m 27s\n",
            "640:\tlearn: 0.2600277\ttotal: 6m 10s\tremaining: 3m 27s\n",
            "641:\tlearn: 0.2597391\ttotal: 6m 10s\tremaining: 3m 26s\n",
            "642:\tlearn: 0.2595689\ttotal: 6m 10s\tremaining: 3m 25s\n",
            "643:\tlearn: 0.2591552\ttotal: 6m 11s\tremaining: 3m 25s\n",
            "644:\tlearn: 0.2589776\ttotal: 6m 11s\tremaining: 3m 24s\n",
            "645:\tlearn: 0.2586521\ttotal: 6m 12s\tremaining: 3m 24s\n",
            "646:\tlearn: 0.2581915\ttotal: 6m 12s\tremaining: 3m 23s\n",
            "647:\tlearn: 0.2572383\ttotal: 6m 13s\tremaining: 3m 22s\n",
            "648:\tlearn: 0.2569294\ttotal: 6m 14s\tremaining: 3m 22s\n",
            "649:\tlearn: 0.2568256\ttotal: 6m 14s\tremaining: 3m 21s\n",
            "650:\tlearn: 0.2566480\ttotal: 6m 15s\tremaining: 3m 21s\n",
            "651:\tlearn: 0.2563980\ttotal: 6m 15s\tremaining: 3m 20s\n",
            "652:\tlearn: 0.2562478\ttotal: 6m 16s\tremaining: 3m 19s\n",
            "653:\tlearn: 0.2556041\ttotal: 6m 16s\tremaining: 3m 19s\n",
            "654:\tlearn: 0.2553185\ttotal: 6m 17s\tremaining: 3m 18s\n",
            "655:\tlearn: 0.2552954\ttotal: 6m 17s\tremaining: 3m 17s\n",
            "656:\tlearn: 0.2551779\ttotal: 6m 18s\tremaining: 3m 17s\n",
            "657:\tlearn: 0.2550095\ttotal: 6m 19s\tremaining: 3m 17s\n",
            "658:\tlearn: 0.2546647\ttotal: 6m 20s\tremaining: 3m 16s\n",
            "659:\tlearn: 0.2545770\ttotal: 6m 20s\tremaining: 3m 16s\n",
            "660:\tlearn: 0.2541983\ttotal: 6m 21s\tremaining: 3m 15s\n",
            "661:\tlearn: 0.2540951\ttotal: 6m 21s\tremaining: 3m 14s\n",
            "662:\tlearn: 0.2539941\ttotal: 6m 22s\tremaining: 3m 14s\n",
            "663:\tlearn: 0.2538773\ttotal: 6m 22s\tremaining: 3m 13s\n",
            "664:\tlearn: 0.2537457\ttotal: 6m 23s\tremaining: 3m 13s\n",
            "665:\tlearn: 0.2536613\ttotal: 6m 23s\tremaining: 3m 12s\n",
            "666:\tlearn: 0.2534945\ttotal: 6m 24s\tremaining: 3m 11s\n",
            "667:\tlearn: 0.2532169\ttotal: 6m 24s\tremaining: 3m 11s\n",
            "668:\tlearn: 0.2530648\ttotal: 6m 25s\tremaining: 3m 10s\n",
            "669:\tlearn: 0.2529345\ttotal: 6m 25s\tremaining: 3m 10s\n",
            "670:\tlearn: 0.2525259\ttotal: 6m 26s\tremaining: 3m 9s\n",
            "671:\tlearn: 0.2523435\ttotal: 6m 26s\tremaining: 3m 8s\n",
            "672:\tlearn: 0.2521663\ttotal: 6m 27s\tremaining: 3m 8s\n",
            "673:\tlearn: 0.2520324\ttotal: 6m 27s\tremaining: 3m 7s\n",
            "674:\tlearn: 0.2507598\ttotal: 6m 28s\tremaining: 3m 7s\n",
            "675:\tlearn: 0.2501587\ttotal: 6m 29s\tremaining: 3m 6s\n",
            "676:\tlearn: 0.2498824\ttotal: 6m 29s\tremaining: 3m 5s\n",
            "677:\tlearn: 0.2496582\ttotal: 6m 30s\tremaining: 3m 5s\n",
            "678:\tlearn: 0.2493895\ttotal: 6m 31s\tremaining: 3m 5s\n",
            "679:\tlearn: 0.2491225\ttotal: 6m 32s\tremaining: 3m 4s\n",
            "680:\tlearn: 0.2487874\ttotal: 6m 32s\tremaining: 3m 3s\n",
            "681:\tlearn: 0.2486403\ttotal: 6m 33s\tremaining: 3m 3s\n",
            "682:\tlearn: 0.2482687\ttotal: 6m 33s\tremaining: 3m 2s\n",
            "683:\tlearn: 0.2481296\ttotal: 6m 34s\tremaining: 3m 2s\n",
            "684:\tlearn: 0.2478359\ttotal: 6m 34s\tremaining: 3m 1s\n",
            "685:\tlearn: 0.2475318\ttotal: 6m 35s\tremaining: 3m 1s\n",
            "686:\tlearn: 0.2471534\ttotal: 6m 36s\tremaining: 3m\n",
            "687:\tlearn: 0.2469478\ttotal: 6m 36s\tremaining: 2m 59s\n",
            "688:\tlearn: 0.2460097\ttotal: 6m 37s\tremaining: 2m 59s\n",
            "689:\tlearn: 0.2458349\ttotal: 6m 37s\tremaining: 2m 58s\n",
            "690:\tlearn: 0.2456482\ttotal: 6m 38s\tremaining: 2m 58s\n",
            "691:\tlearn: 0.2455070\ttotal: 6m 38s\tremaining: 2m 57s\n",
            "692:\tlearn: 0.2453690\ttotal: 6m 39s\tremaining: 2m 56s\n",
            "693:\tlearn: 0.2451942\ttotal: 6m 39s\tremaining: 2m 56s\n",
            "694:\tlearn: 0.2448339\ttotal: 6m 40s\tremaining: 2m 55s\n",
            "695:\tlearn: 0.2446749\ttotal: 6m 40s\tremaining: 2m 55s\n",
            "696:\tlearn: 0.2439870\ttotal: 6m 41s\tremaining: 2m 54s\n",
            "697:\tlearn: 0.2438471\ttotal: 6m 41s\tremaining: 2m 53s\n",
            "698:\tlearn: 0.2436862\ttotal: 6m 42s\tremaining: 2m 53s\n",
            "699:\tlearn: 0.2433920\ttotal: 6m 43s\tremaining: 2m 52s\n",
            "700:\tlearn: 0.2431875\ttotal: 6m 44s\tremaining: 2m 52s\n",
            "701:\tlearn: 0.2427477\ttotal: 6m 45s\tremaining: 2m 51s\n",
            "702:\tlearn: 0.2426157\ttotal: 6m 45s\tremaining: 2m 51s\n",
            "703:\tlearn: 0.2420767\ttotal: 6m 46s\tremaining: 2m 50s\n",
            "704:\tlearn: 0.2419030\ttotal: 6m 46s\tremaining: 2m 50s\n",
            "705:\tlearn: 0.2413955\ttotal: 6m 47s\tremaining: 2m 49s\n",
            "706:\tlearn: 0.2412261\ttotal: 6m 48s\tremaining: 2m 49s\n",
            "707:\tlearn: 0.2410063\ttotal: 6m 48s\tremaining: 2m 48s\n",
            "708:\tlearn: 0.2408958\ttotal: 6m 49s\tremaining: 2m 47s\n",
            "709:\tlearn: 0.2400660\ttotal: 6m 49s\tremaining: 2m 47s\n",
            "710:\tlearn: 0.2398124\ttotal: 6m 50s\tremaining: 2m 46s\n",
            "711:\tlearn: 0.2395902\ttotal: 6m 50s\tremaining: 2m 46s\n",
            "712:\tlearn: 0.2391435\ttotal: 6m 51s\tremaining: 2m 45s\n",
            "713:\tlearn: 0.2389606\ttotal: 6m 51s\tremaining: 2m 44s\n",
            "714:\tlearn: 0.2385836\ttotal: 6m 52s\tremaining: 2m 44s\n",
            "715:\tlearn: 0.2382196\ttotal: 6m 52s\tremaining: 2m 43s\n",
            "716:\tlearn: 0.2375419\ttotal: 6m 53s\tremaining: 2m 43s\n",
            "717:\tlearn: 0.2373183\ttotal: 6m 54s\tremaining: 2m 42s\n",
            "718:\tlearn: 0.2370920\ttotal: 6m 54s\tremaining: 2m 42s\n",
            "719:\tlearn: 0.2365753\ttotal: 6m 55s\tremaining: 2m 41s\n",
            "720:\tlearn: 0.2364570\ttotal: 6m 56s\tremaining: 2m 41s\n",
            "721:\tlearn: 0.2363942\ttotal: 6m 57s\tremaining: 2m 40s\n",
            "722:\tlearn: 0.2363606\ttotal: 6m 57s\tremaining: 2m 40s\n",
            "723:\tlearn: 0.2361089\ttotal: 6m 58s\tremaining: 2m 39s\n",
            "724:\tlearn: 0.2360856\ttotal: 6m 58s\tremaining: 2m 38s\n",
            "725:\tlearn: 0.2359108\ttotal: 6m 59s\tremaining: 2m 38s\n",
            "726:\tlearn: 0.2357918\ttotal: 6m 59s\tremaining: 2m 37s\n",
            "727:\tlearn: 0.2357621\ttotal: 7m\tremaining: 2m 37s\n",
            "728:\tlearn: 0.2355640\ttotal: 7m\tremaining: 2m 36s\n",
            "729:\tlearn: 0.2355403\ttotal: 7m 1s\tremaining: 2m 35s\n",
            "730:\tlearn: 0.2354177\ttotal: 7m 1s\tremaining: 2m 35s\n",
            "731:\tlearn: 0.2351672\ttotal: 7m 2s\tremaining: 2m 34s\n",
            "732:\tlearn: 0.2345625\ttotal: 7m 2s\tremaining: 2m 34s\n",
            "733:\tlearn: 0.2344959\ttotal: 7m 3s\tremaining: 2m 33s\n",
            "734:\tlearn: 0.2329106\ttotal: 7m 3s\tremaining: 2m 32s\n",
            "735:\tlearn: 0.2327338\ttotal: 7m 4s\tremaining: 2m 32s\n",
            "736:\tlearn: 0.2326524\ttotal: 7m 4s\tremaining: 2m 31s\n",
            "737:\tlearn: 0.2323047\ttotal: 7m 5s\tremaining: 2m 31s\n",
            "738:\tlearn: 0.2319146\ttotal: 7m 6s\tremaining: 2m 30s\n",
            "739:\tlearn: 0.2317293\ttotal: 7m 6s\tremaining: 2m 29s\n",
            "740:\tlearn: 0.2315897\ttotal: 7m 7s\tremaining: 2m 29s\n",
            "741:\tlearn: 0.2315055\ttotal: 7m 8s\tremaining: 2m 28s\n",
            "742:\tlearn: 0.2310158\ttotal: 7m 9s\tremaining: 2m 28s\n",
            "743:\tlearn: 0.2306840\ttotal: 7m 9s\tremaining: 2m 27s\n",
            "744:\tlearn: 0.2304734\ttotal: 7m 10s\tremaining: 2m 27s\n",
            "745:\tlearn: 0.2303134\ttotal: 7m 10s\tremaining: 2m 26s\n",
            "746:\tlearn: 0.2299920\ttotal: 7m 11s\tremaining: 2m 26s\n",
            "747:\tlearn: 0.2295938\ttotal: 7m 12s\tremaining: 2m 25s\n",
            "748:\tlearn: 0.2289856\ttotal: 7m 12s\tremaining: 2m 25s\n",
            "749:\tlearn: 0.2287511\ttotal: 7m 13s\tremaining: 2m 24s\n",
            "750:\tlearn: 0.2285035\ttotal: 7m 13s\tremaining: 2m 23s\n",
            "751:\tlearn: 0.2284096\ttotal: 7m 14s\tremaining: 2m 23s\n",
            "752:\tlearn: 0.2283874\ttotal: 7m 14s\tremaining: 2m 22s\n",
            "753:\tlearn: 0.2282665\ttotal: 7m 15s\tremaining: 2m 22s\n",
            "754:\tlearn: 0.2279465\ttotal: 7m 15s\tremaining: 2m 21s\n",
            "755:\tlearn: 0.2276690\ttotal: 7m 16s\tremaining: 2m 20s\n",
            "756:\tlearn: 0.2276329\ttotal: 7m 16s\tremaining: 2m 20s\n",
            "757:\tlearn: 0.2274763\ttotal: 7m 17s\tremaining: 2m 19s\n",
            "758:\tlearn: 0.2272054\ttotal: 7m 17s\tremaining: 2m 19s\n",
            "759:\tlearn: 0.2268849\ttotal: 7m 18s\tremaining: 2m 18s\n",
            "760:\tlearn: 0.2268557\ttotal: 7m 18s\tremaining: 2m 17s\n",
            "761:\tlearn: 0.2267183\ttotal: 7m 19s\tremaining: 2m 17s\n",
            "762:\tlearn: 0.2265898\ttotal: 7m 20s\tremaining: 2m 16s\n",
            "763:\tlearn: 0.2264969\ttotal: 7m 21s\tremaining: 2m 16s\n",
            "764:\tlearn: 0.2262269\ttotal: 7m 21s\tremaining: 2m 15s\n",
            "765:\tlearn: 0.2259805\ttotal: 7m 22s\tremaining: 2m 15s\n",
            "766:\tlearn: 0.2258705\ttotal: 7m 22s\tremaining: 2m 14s\n",
            "767:\tlearn: 0.2256970\ttotal: 7m 23s\tremaining: 2m 13s\n",
            "768:\tlearn: 0.2255182\ttotal: 7m 23s\tremaining: 2m 13s\n",
            "769:\tlearn: 0.2254280\ttotal: 7m 24s\tremaining: 2m 12s\n",
            "770:\tlearn: 0.2254048\ttotal: 7m 24s\tremaining: 2m 12s\n",
            "771:\tlearn: 0.2253129\ttotal: 7m 25s\tremaining: 2m 11s\n",
            "772:\tlearn: 0.2249217\ttotal: 7m 25s\tremaining: 2m 10s\n",
            "773:\tlearn: 0.2247583\ttotal: 7m 26s\tremaining: 2m 10s\n",
            "774:\tlearn: 0.2243398\ttotal: 7m 27s\tremaining: 2m 9s\n",
            "775:\tlearn: 0.2242206\ttotal: 7m 27s\tremaining: 2m 9s\n",
            "776:\tlearn: 0.2239572\ttotal: 7m 27s\tremaining: 2m 8s\n",
            "777:\tlearn: 0.2237898\ttotal: 7m 28s\tremaining: 2m 8s\n",
            "778:\tlearn: 0.2236182\ttotal: 7m 29s\tremaining: 2m 7s\n",
            "779:\tlearn: 0.2233615\ttotal: 7m 29s\tremaining: 2m 6s\n",
            "780:\tlearn: 0.2231578\ttotal: 7m 30s\tremaining: 2m 6s\n",
            "781:\tlearn: 0.2230085\ttotal: 7m 30s\tremaining: 2m 5s\n",
            "782:\tlearn: 0.2228825\ttotal: 7m 31s\tremaining: 2m 5s\n",
            "783:\tlearn: 0.2224731\ttotal: 7m 32s\tremaining: 2m 4s\n",
            "784:\tlearn: 0.2222177\ttotal: 7m 33s\tremaining: 2m 4s\n",
            "785:\tlearn: 0.2220775\ttotal: 7m 34s\tremaining: 2m 3s\n",
            "786:\tlearn: 0.2219026\ttotal: 7m 34s\tremaining: 2m 3s\n",
            "787:\tlearn: 0.2215467\ttotal: 7m 35s\tremaining: 2m 2s\n",
            "788:\tlearn: 0.2213668\ttotal: 7m 35s\tremaining: 2m 1s\n",
            "789:\tlearn: 0.2211103\ttotal: 7m 36s\tremaining: 2m 1s\n",
            "790:\tlearn: 0.2209320\ttotal: 7m 37s\tremaining: 2m\n",
            "791:\tlearn: 0.2208537\ttotal: 7m 37s\tremaining: 2m\n",
            "792:\tlearn: 0.2206261\ttotal: 7m 38s\tremaining: 1m 59s\n",
            "793:\tlearn: 0.2204041\ttotal: 7m 38s\tremaining: 1m 59s\n",
            "794:\tlearn: 0.2200436\ttotal: 7m 39s\tremaining: 1m 58s\n",
            "795:\tlearn: 0.2197397\ttotal: 7m 39s\tremaining: 1m 57s\n",
            "796:\tlearn: 0.2197127\ttotal: 7m 40s\tremaining: 1m 57s\n",
            "797:\tlearn: 0.2191585\ttotal: 7m 40s\tremaining: 1m 56s\n",
            "798:\tlearn: 0.2190473\ttotal: 7m 41s\tremaining: 1m 56s\n",
            "799:\tlearn: 0.2188179\ttotal: 7m 41s\tremaining: 1m 55s\n",
            "800:\tlearn: 0.2185903\ttotal: 7m 42s\tremaining: 1m 54s\n",
            "801:\tlearn: 0.2184908\ttotal: 7m 43s\tremaining: 1m 54s\n",
            "802:\tlearn: 0.2180717\ttotal: 7m 43s\tremaining: 1m 53s\n",
            "803:\tlearn: 0.2179974\ttotal: 7m 44s\tremaining: 1m 53s\n",
            "804:\tlearn: 0.2177485\ttotal: 7m 45s\tremaining: 1m 52s\n",
            "805:\tlearn: 0.2172223\ttotal: 7m 46s\tremaining: 1m 52s\n",
            "806:\tlearn: 0.2169362\ttotal: 7m 47s\tremaining: 1m 51s\n",
            "807:\tlearn: 0.2165386\ttotal: 7m 47s\tremaining: 1m 51s\n",
            "808:\tlearn: 0.2163869\ttotal: 7m 48s\tremaining: 1m 50s\n",
            "809:\tlearn: 0.2162614\ttotal: 7m 48s\tremaining: 1m 49s\n",
            "810:\tlearn: 0.2159512\ttotal: 7m 49s\tremaining: 1m 49s\n",
            "811:\tlearn: 0.2159116\ttotal: 7m 49s\tremaining: 1m 48s\n",
            "812:\tlearn: 0.2155592\ttotal: 7m 50s\tremaining: 1m 48s\n",
            "813:\tlearn: 0.2144279\ttotal: 7m 51s\tremaining: 1m 47s\n",
            "814:\tlearn: 0.2142803\ttotal: 7m 51s\tremaining: 1m 47s\n",
            "815:\tlearn: 0.2139225\ttotal: 7m 53s\tremaining: 1m 46s\n",
            "816:\tlearn: 0.2124660\ttotal: 7m 53s\tremaining: 1m 46s\n",
            "817:\tlearn: 0.2123598\ttotal: 7m 54s\tremaining: 1m 45s\n",
            "818:\tlearn: 0.2122064\ttotal: 7m 54s\tremaining: 1m 44s\n",
            "819:\tlearn: 0.2119987\ttotal: 7m 55s\tremaining: 1m 44s\n",
            "820:\tlearn: 0.2114952\ttotal: 7m 55s\tremaining: 1m 43s\n",
            "821:\tlearn: 0.2113176\ttotal: 7m 56s\tremaining: 1m 43s\n",
            "822:\tlearn: 0.2112753\ttotal: 7m 56s\tremaining: 1m 42s\n",
            "823:\tlearn: 0.2112532\ttotal: 7m 57s\tremaining: 1m 41s\n",
            "824:\tlearn: 0.2110340\ttotal: 7m 58s\tremaining: 1m 41s\n",
            "825:\tlearn: 0.2107284\ttotal: 7m 59s\tremaining: 1m 40s\n",
            "826:\tlearn: 0.2106213\ttotal: 7m 59s\tremaining: 1m 40s\n",
            "827:\tlearn: 0.2102690\ttotal: 8m\tremaining: 1m 39s\n",
            "828:\tlearn: 0.2099680\ttotal: 8m\tremaining: 1m 39s\n",
            "829:\tlearn: 0.2094317\ttotal: 8m 1s\tremaining: 1m 38s\n",
            "830:\tlearn: 0.2092084\ttotal: 8m 1s\tremaining: 1m 37s\n",
            "831:\tlearn: 0.2091365\ttotal: 8m 2s\tremaining: 1m 37s\n",
            "832:\tlearn: 0.2090364\ttotal: 8m 2s\tremaining: 1m 36s\n",
            "833:\tlearn: 0.2087903\ttotal: 8m 3s\tremaining: 1m 36s\n",
            "834:\tlearn: 0.2086731\ttotal: 8m 3s\tremaining: 1m 35s\n",
            "835:\tlearn: 0.2084704\ttotal: 8m 4s\tremaining: 1m 35s\n",
            "836:\tlearn: 0.2080860\ttotal: 8m 4s\tremaining: 1m 34s\n",
            "837:\tlearn: 0.2079515\ttotal: 8m 5s\tremaining: 1m 33s\n",
            "838:\tlearn: 0.2078614\ttotal: 8m 5s\tremaining: 1m 33s\n",
            "839:\tlearn: 0.2078380\ttotal: 8m 6s\tremaining: 1m 32s\n",
            "840:\tlearn: 0.2076783\ttotal: 8m 6s\tremaining: 1m 32s\n",
            "841:\tlearn: 0.2074308\ttotal: 8m 7s\tremaining: 1m 31s\n",
            "842:\tlearn: 0.2072106\ttotal: 8m 7s\tremaining: 1m 30s\n",
            "843:\tlearn: 0.2069687\ttotal: 8m 8s\tremaining: 1m 30s\n",
            "844:\tlearn: 0.2069371\ttotal: 8m 8s\tremaining: 1m 29s\n",
            "845:\tlearn: 0.2066508\ttotal: 8m 9s\tremaining: 1m 29s\n",
            "846:\tlearn: 0.2061474\ttotal: 8m 10s\tremaining: 1m 28s\n",
            "847:\tlearn: 0.2061224\ttotal: 8m 11s\tremaining: 1m 28s\n",
            "848:\tlearn: 0.2061009\ttotal: 8m 11s\tremaining: 1m 27s\n",
            "849:\tlearn: 0.2059861\ttotal: 8m 12s\tremaining: 1m 26s\n",
            "850:\tlearn: 0.2056833\ttotal: 8m 12s\tremaining: 1m 26s\n",
            "851:\tlearn: 0.2053593\ttotal: 8m 13s\tremaining: 1m 25s\n",
            "852:\tlearn: 0.2050099\ttotal: 8m 14s\tremaining: 1m 25s\n",
            "853:\tlearn: 0.2047111\ttotal: 8m 14s\tremaining: 1m 24s\n",
            "854:\tlearn: 0.2045354\ttotal: 8m 14s\tremaining: 1m 23s\n",
            "855:\tlearn: 0.2043806\ttotal: 8m 15s\tremaining: 1m 23s\n",
            "856:\tlearn: 0.2040712\ttotal: 8m 16s\tremaining: 1m 22s\n",
            "857:\tlearn: 0.2039911\ttotal: 8m 16s\tremaining: 1m 22s\n",
            "858:\tlearn: 0.2038749\ttotal: 8m 17s\tremaining: 1m 21s\n",
            "859:\tlearn: 0.2036991\ttotal: 8m 17s\tremaining: 1m 21s\n",
            "860:\tlearn: 0.2035861\ttotal: 8m 18s\tremaining: 1m 20s\n",
            "861:\tlearn: 0.2035515\ttotal: 8m 18s\tremaining: 1m 19s\n",
            "862:\tlearn: 0.2034436\ttotal: 8m 19s\tremaining: 1m 19s\n",
            "863:\tlearn: 0.2032821\ttotal: 8m 19s\tremaining: 1m 18s\n",
            "864:\tlearn: 0.2029611\ttotal: 8m 20s\tremaining: 1m 18s\n",
            "865:\tlearn: 0.2024726\ttotal: 8m 21s\tremaining: 1m 17s\n",
            "866:\tlearn: 0.2017085\ttotal: 8m 21s\tremaining: 1m 16s\n",
            "867:\tlearn: 0.2004077\ttotal: 8m 22s\tremaining: 1m 16s\n",
            "868:\tlearn: 0.2002633\ttotal: 8m 23s\tremaining: 1m 15s\n",
            "869:\tlearn: 0.1998808\ttotal: 8m 24s\tremaining: 1m 15s\n",
            "870:\tlearn: 0.1995482\ttotal: 8m 24s\tremaining: 1m 14s\n",
            "871:\tlearn: 0.1993173\ttotal: 8m 25s\tremaining: 1m 14s\n",
            "872:\tlearn: 0.1991805\ttotal: 8m 25s\tremaining: 1m 13s\n",
            "873:\tlearn: 0.1991573\ttotal: 8m 26s\tremaining: 1m 13s\n",
            "874:\tlearn: 0.1987358\ttotal: 8m 27s\tremaining: 1m 12s\n",
            "875:\tlearn: 0.1983848\ttotal: 8m 27s\tremaining: 1m 11s\n",
            "876:\tlearn: 0.1982319\ttotal: 8m 28s\tremaining: 1m 11s\n",
            "877:\tlearn: 0.1978127\ttotal: 8m 28s\tremaining: 1m 10s\n",
            "878:\tlearn: 0.1977377\ttotal: 8m 29s\tremaining: 1m 10s\n",
            "879:\tlearn: 0.1973459\ttotal: 8m 29s\tremaining: 1m 9s\n",
            "880:\tlearn: 0.1972643\ttotal: 8m 30s\tremaining: 1m 8s\n",
            "881:\tlearn: 0.1971269\ttotal: 8m 30s\tremaining: 1m 8s\n",
            "882:\tlearn: 0.1970013\ttotal: 8m 31s\tremaining: 1m 7s\n",
            "883:\tlearn: 0.1969782\ttotal: 8m 31s\tremaining: 1m 7s\n",
            "884:\tlearn: 0.1968609\ttotal: 8m 32s\tremaining: 1m 6s\n",
            "885:\tlearn: 0.1967670\ttotal: 8m 32s\tremaining: 1m 5s\n",
            "886:\tlearn: 0.1961045\ttotal: 8m 33s\tremaining: 1m 5s\n",
            "887:\tlearn: 0.1958526\ttotal: 8m 33s\tremaining: 1m 4s\n",
            "888:\tlearn: 0.1958264\ttotal: 8m 34s\tremaining: 1m 4s\n",
            "889:\tlearn: 0.1957325\ttotal: 8m 35s\tremaining: 1m 3s\n",
            "890:\tlearn: 0.1956514\ttotal: 8m 36s\tremaining: 1m 3s\n",
            "891:\tlearn: 0.1954774\ttotal: 8m 36s\tremaining: 1m 2s\n",
            "892:\tlearn: 0.1952972\ttotal: 8m 37s\tremaining: 1m 1s\n",
            "893:\tlearn: 0.1949839\ttotal: 8m 37s\tremaining: 1m 1s\n",
            "894:\tlearn: 0.1948683\ttotal: 8m 38s\tremaining: 1m\n",
            "895:\tlearn: 0.1947004\ttotal: 8m 38s\tremaining: 1m\n",
            "896:\tlearn: 0.1945875\ttotal: 8m 39s\tremaining: 59.6s\n",
            "897:\tlearn: 0.1940233\ttotal: 8m 40s\tremaining: 59.1s\n",
            "898:\tlearn: 0.1938758\ttotal: 8m 40s\tremaining: 58.5s\n",
            "899:\tlearn: 0.1937297\ttotal: 8m 41s\tremaining: 57.9s\n",
            "900:\tlearn: 0.1934463\ttotal: 8m 41s\tremaining: 57.3s\n",
            "901:\tlearn: 0.1934238\ttotal: 8m 42s\tremaining: 56.7s\n",
            "902:\tlearn: 0.1933931\ttotal: 8m 42s\tremaining: 56.1s\n",
            "903:\tlearn: 0.1932417\ttotal: 8m 42s\tremaining: 55.5s\n",
            "904:\tlearn: 0.1928794\ttotal: 8m 43s\tremaining: 55s\n",
            "905:\tlearn: 0.1921719\ttotal: 8m 44s\tremaining: 54.4s\n",
            "906:\tlearn: 0.1920267\ttotal: 8m 44s\tremaining: 53.8s\n",
            "907:\tlearn: 0.1917012\ttotal: 8m 45s\tremaining: 53.2s\n",
            "908:\tlearn: 0.1912127\ttotal: 8m 45s\tremaining: 52.7s\n",
            "909:\tlearn: 0.1908519\ttotal: 8m 46s\tremaining: 52.1s\n",
            "910:\tlearn: 0.1907534\ttotal: 8m 47s\tremaining: 51.5s\n",
            "911:\tlearn: 0.1906664\ttotal: 8m 48s\tremaining: 51s\n",
            "912:\tlearn: 0.1906152\ttotal: 8m 48s\tremaining: 50.4s\n",
            "913:\tlearn: 0.1904274\ttotal: 8m 49s\tremaining: 49.8s\n",
            "914:\tlearn: 0.1900754\ttotal: 8m 49s\tremaining: 49.2s\n",
            "915:\tlearn: 0.1896017\ttotal: 8m 50s\tremaining: 48.7s\n",
            "916:\tlearn: 0.1892265\ttotal: 8m 51s\tremaining: 48.1s\n",
            "917:\tlearn: 0.1890057\ttotal: 8m 51s\tremaining: 47.5s\n",
            "918:\tlearn: 0.1888967\ttotal: 8m 52s\tremaining: 46.9s\n",
            "919:\tlearn: 0.1886714\ttotal: 8m 52s\tremaining: 46.3s\n",
            "920:\tlearn: 0.1885808\ttotal: 8m 53s\tremaining: 45.7s\n",
            "921:\tlearn: 0.1885333\ttotal: 8m 53s\tremaining: 45.2s\n",
            "922:\tlearn: 0.1883690\ttotal: 8m 54s\tremaining: 44.6s\n",
            "923:\tlearn: 0.1878857\ttotal: 8m 54s\tremaining: 44s\n",
            "924:\tlearn: 0.1876808\ttotal: 8m 55s\tremaining: 43.4s\n",
            "925:\tlearn: 0.1871480\ttotal: 8m 55s\tremaining: 42.8s\n",
            "926:\tlearn: 0.1871197\ttotal: 8m 56s\tremaining: 42.2s\n",
            "927:\tlearn: 0.1868369\ttotal: 8m 56s\tremaining: 41.7s\n",
            "928:\tlearn: 0.1848794\ttotal: 8m 57s\tremaining: 41.1s\n",
            "929:\tlearn: 0.1844405\ttotal: 8m 58s\tremaining: 40.5s\n",
            "930:\tlearn: 0.1844199\ttotal: 8m 58s\tremaining: 39.9s\n",
            "931:\tlearn: 0.1840567\ttotal: 8m 59s\tremaining: 39.4s\n",
            "932:\tlearn: 0.1837758\ttotal: 9m\tremaining: 38.8s\n",
            "933:\tlearn: 0.1836668\ttotal: 9m 1s\tremaining: 38.3s\n",
            "934:\tlearn: 0.1834803\ttotal: 9m 2s\tremaining: 37.7s\n",
            "935:\tlearn: 0.1832006\ttotal: 9m 2s\tremaining: 37.1s\n",
            "936:\tlearn: 0.1830179\ttotal: 9m 3s\tremaining: 36.5s\n",
            "937:\tlearn: 0.1825338\ttotal: 9m 3s\tremaining: 36s\n",
            "938:\tlearn: 0.1825094\ttotal: 9m 4s\tremaining: 35.4s\n",
            "939:\tlearn: 0.1823855\ttotal: 9m 4s\tremaining: 34.8s\n",
            "940:\tlearn: 0.1823159\ttotal: 9m 5s\tremaining: 34.2s\n",
            "941:\tlearn: 0.1819999\ttotal: 9m 5s\tremaining: 33.6s\n",
            "942:\tlearn: 0.1818202\ttotal: 9m 6s\tremaining: 33s\n",
            "943:\tlearn: 0.1817535\ttotal: 9m 6s\tremaining: 32.4s\n",
            "944:\tlearn: 0.1816797\ttotal: 9m 7s\tremaining: 31.9s\n",
            "945:\tlearn: 0.1816273\ttotal: 9m 7s\tremaining: 31.3s\n",
            "946:\tlearn: 0.1812203\ttotal: 9m 8s\tremaining: 30.7s\n",
            "947:\tlearn: 0.1811167\ttotal: 9m 9s\tremaining: 30.1s\n",
            "948:\tlearn: 0.1810958\ttotal: 9m 9s\tremaining: 29.5s\n",
            "949:\tlearn: 0.1809706\ttotal: 9m 10s\tremaining: 28.9s\n",
            "950:\tlearn: 0.1807339\ttotal: 9m 10s\tremaining: 28.4s\n",
            "951:\tlearn: 0.1805947\ttotal: 9m 11s\tremaining: 27.8s\n",
            "952:\tlearn: 0.1804194\ttotal: 9m 12s\tremaining: 27.2s\n",
            "953:\tlearn: 0.1802274\ttotal: 9m 13s\tremaining: 26.7s\n",
            "954:\tlearn: 0.1799486\ttotal: 9m 13s\tremaining: 26.1s\n",
            "955:\tlearn: 0.1797603\ttotal: 9m 14s\tremaining: 25.5s\n",
            "956:\tlearn: 0.1795705\ttotal: 9m 15s\tremaining: 24.9s\n",
            "957:\tlearn: 0.1793831\ttotal: 9m 15s\tremaining: 24.4s\n",
            "958:\tlearn: 0.1793090\ttotal: 9m 16s\tremaining: 23.8s\n",
            "959:\tlearn: 0.1789431\ttotal: 9m 16s\tremaining: 23.2s\n",
            "960:\tlearn: 0.1788916\ttotal: 9m 17s\tremaining: 22.6s\n",
            "961:\tlearn: 0.1787478\ttotal: 9m 17s\tremaining: 22s\n",
            "962:\tlearn: 0.1784600\ttotal: 9m 18s\tremaining: 21.4s\n",
            "963:\tlearn: 0.1783087\ttotal: 9m 18s\tremaining: 20.9s\n",
            "964:\tlearn: 0.1781055\ttotal: 9m 19s\tremaining: 20.3s\n",
            "965:\tlearn: 0.1780424\ttotal: 9m 19s\tremaining: 19.7s\n",
            "966:\tlearn: 0.1778823\ttotal: 9m 20s\tremaining: 19.1s\n",
            "967:\tlearn: 0.1776940\ttotal: 9m 20s\tremaining: 18.5s\n",
            "968:\tlearn: 0.1775379\ttotal: 9m 21s\tremaining: 18s\n",
            "969:\tlearn: 0.1773988\ttotal: 9m 21s\tremaining: 17.4s\n",
            "970:\tlearn: 0.1771924\ttotal: 9m 22s\tremaining: 16.8s\n",
            "971:\tlearn: 0.1770474\ttotal: 9m 22s\tremaining: 16.2s\n",
            "972:\tlearn: 0.1767383\ttotal: 9m 23s\tremaining: 15.6s\n",
            "973:\tlearn: 0.1766926\ttotal: 9m 24s\tremaining: 15.1s\n",
            "974:\tlearn: 0.1765720\ttotal: 9m 25s\tremaining: 14.5s\n",
            "975:\tlearn: 0.1765483\ttotal: 9m 26s\tremaining: 13.9s\n",
            "976:\tlearn: 0.1764265\ttotal: 9m 26s\tremaining: 13.3s\n",
            "977:\tlearn: 0.1760633\ttotal: 9m 27s\tremaining: 12.8s\n",
            "978:\tlearn: 0.1755040\ttotal: 9m 27s\tremaining: 12.2s\n",
            "979:\tlearn: 0.1754214\ttotal: 9m 28s\tremaining: 11.6s\n",
            "980:\tlearn: 0.1753987\ttotal: 9m 28s\tremaining: 11s\n",
            "981:\tlearn: 0.1752939\ttotal: 9m 29s\tremaining: 10.4s\n",
            "982:\tlearn: 0.1752080\ttotal: 9m 29s\tremaining: 9.86s\n",
            "983:\tlearn: 0.1751838\ttotal: 9m 30s\tremaining: 9.28s\n",
            "984:\tlearn: 0.1749887\ttotal: 9m 30s\tremaining: 8.69s\n",
            "985:\tlearn: 0.1749649\ttotal: 9m 31s\tremaining: 8.11s\n",
            "986:\tlearn: 0.1749017\ttotal: 9m 31s\tremaining: 7.53s\n",
            "987:\tlearn: 0.1748422\ttotal: 9m 32s\tremaining: 6.95s\n",
            "988:\tlearn: 0.1748157\ttotal: 9m 32s\tremaining: 6.37s\n",
            "989:\tlearn: 0.1747924\ttotal: 9m 33s\tremaining: 5.79s\n",
            "990:\tlearn: 0.1745756\ttotal: 9m 33s\tremaining: 5.21s\n",
            "991:\tlearn: 0.1743846\ttotal: 9m 34s\tremaining: 4.63s\n",
            "992:\tlearn: 0.1737939\ttotal: 9m 35s\tremaining: 4.05s\n",
            "993:\tlearn: 0.1734578\ttotal: 9m 35s\tremaining: 3.47s\n",
            "994:\tlearn: 0.1728309\ttotal: 9m 35s\tremaining: 2.89s\n",
            "995:\tlearn: 0.1727823\ttotal: 9m 36s\tremaining: 2.32s\n",
            "996:\tlearn: 0.1726718\ttotal: 9m 37s\tremaining: 1.74s\n",
            "997:\tlearn: 0.1724751\ttotal: 9m 38s\tremaining: 1.16s\n",
            "998:\tlearn: 0.1722702\ttotal: 9m 39s\tremaining: 580ms\n",
            "999:\tlearn: 0.1720551\ttotal: 9m 39s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7fcf7ceff700>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "CatBoostClassifier=CatBoostClassifier(iterations=1000,\n",
        "                           learning_rate=1,\n",
        "                           depth=3)\n",
        "CatBoostClassifier.fit(X_train_not,y_train_not)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "UFFEnN5YophK"
      },
      "outputs": [],
      "source": [
        "y_pred_cat=CatBoostClassifier.predict(X_test_not)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "xro-PbYfophL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f8bfb2-1014-4125-900e-35bee5bceed7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.859125"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "accuaracy_cat=accuracy_score(y_test_not,y_pred_cat)\n",
        "accuaracy_cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "e7ZivCDhqF3F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e40b3fe2-024c-46d6-c700-28152ec2cb65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8584134823515712"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "score=f1_score(y_test_not,y_pred_cat,average='weighted')\n",
        "score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "wUffhyflophL"
      },
      "outputs": [],
      "source": [
        "pickle.dump(CatBoostClassifier,open(\"CatBoostClassifier.pkl\",'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FEIj5cbq5rN"
      },
      "source": [
        "# ***XGB***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "aZIYL13_o9Uc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "d74c5e7e-8175-425f-a329-aaa6d9ca987d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
              "              objective='multi:softprob', predictor=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "xgb_model = XGBClassifier(objective=\"multi:softprob\", random_state=5, n_estimators=300)\n",
        "xgb_model.fit(X_train_not,y_train_not)#1.5h for this accurcy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "zGBA4idCo9Ud"
      },
      "outputs": [],
      "source": [
        "y_pred_XG=xgb_model.predict(X_test_not)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "uE0-yUNyo9Ue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d6908bc-a723-429b-dc83-fa71ae260c91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.901375"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "accuaracy_XG=accuracy_score(y_test_not,y_pred_XG)\n",
        "accuaracy_XG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "hILYETI-qPIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d51f38-0bc2-4e2d-84a9-437534e0ed64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9008571305838209"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "score=f1_score(y_test_not,y_pred_XG,average='weighted')\n",
        "score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMZ6ajPDo9Ue"
      },
      "outputs": [],
      "source": [
        "pickle.dump(xgb_model,open(\"XG.pkl\",'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYqI7KFBDOHZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMiMOV5REGwM"
      },
      "source": [
        "the faster with v.good accurcy :CatBoost -->XG,,,,\n",
        "the slowest  with v.good accurcy:stack,,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRz6B2lgqpHQ"
      },
      "outputs": [],
      "source": [
        "y_predtest_XG=xgb_model.predict(datatest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyipPAljq93n"
      },
      "outputs": [],
      "source": [
        "submission_id=pd.DataFrame(np.arange(0,10000,1))\n",
        "submission_label=pd.DataFrame(data=y_predtest_XG).astype('int')\n",
        "submission_id.insert(1, column = \"Label\", value =submission_label)  \n",
        "#submission_id.rename(columns={\"0\": \"Id\"}, inplace=True)\n",
        "submission_id.columns = [\"Id\", \"Label\"]\n",
        "submission_id.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjiAqiOqs3m9"
      },
      "outputs": [],
      "source": [
        "submission_id.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in7rePflt7wQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}